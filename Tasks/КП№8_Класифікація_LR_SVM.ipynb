{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNhBviOWN-YW"
      },
      "source": [
        "<center><font size=\"6\"><b>Комп'ютерний практикум 8.\n",
        "\n",
        "<center><b> Методи класифікації </font>\n",
        "\n",
        "\n",
        "<center><b><i><font size=\"4\"> LR (Logistic Regression)\n",
        "\n",
        "SVM(Support Vector Machine)</b></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtM5UAzB8LpF"
      },
      "source": [
        "##__Логістична регресія (LR - Logistic Regression))__\n",
        "\n",
        "Логістична регресія є частинним випадком лінійного бінарного класифікатора, яка повертає значення функції у межах від $0$ до $1$, що можна інтерпретувати як ймовірність $p_+$ того, що об'єкт $\\vec{x_i}$ відноситься до классу $\"+\"$:\n",
        "\n",
        "\n",
        "$$\\large p_+ = P\\left(y_i = 1 \\mid \\vec{x_i}, \\vec{w}\\right) $$\n",
        "\n",
        "\n",
        "Прогнозування не просто відповіді, а саме ймовірності віднесення до класу $\"+\"$ в багатьох задачах є важливою бізнес-вимогою. Наприклад, в задачах кредитного скорингу, де застосовується  логістична регресія, часто прогнозують ймовірність неповернення кредиту ($p_+$). Клієнті сортують по цій передбачуваній ймовірності (за спаданням), і отримують скоркарту — по суті, рейтинг клієнтів від \"ненадійних\" до \"надійних\".\n",
        "\n",
        "За допомогою ЛР ми хочемо спрогнозувати ймовірність $p_+ \\in [0,1]$. Лінійна регресія за допомогою МНК дає можливість побудувати лінійний прогноз: $b(\\vec{x}) = \\vec{w}^T \\vec{x} \\in \\mathbb{R}$. \n",
        "\n",
        "Для того,т щоб перетворити отримане значення в ймовірність необхідна функція $f: \\mathbb{R} \\rightarrow [0,1].$ \n",
        "\n",
        "В моделі логістичної регресії береться функція ___\"сігмоїда\" (логіт-функція)___: $$\\sigma(z) = \\frac{1}{1 + \\exp^{-z}}$$. \n",
        "\n",
        "\n",
        "<center><img src=\"https://static.javatpoint.com/tutorial/machine-learning/images/logistic-regression-in-machine-learning.png\" width=\"400\"></center>\n",
        "\n",
        "Позначимо $P(X)$ ймовірність події $X$. Тоді відношення ймовірностей $OR(X)$ визначається з $\\frac{P(X)}{1-P(X)}$ — відношення ймовірностей того, відбудеться подія чи ні. Ймовірність та відношення шансів містять однакову інформацію. Проте, $P(X)$ знаходится в межах від $0$ до $1$, а $OR(X)$ - в межах від $0$ до $\\infty$.\n",
        "\n",
        "\n",
        "Якщо прологарифмувати $OR(X)$, то $\\log{OR(X)} \\in \\mathbb{R}$. його і будемо прогнозувати методом МНК.\n",
        "\n",
        "Логістична регресія буде робити прогноз $p_+ = P\\left(y_i = 1 \\mid \\vec{x_i}, \\vec{w}\\right)$.\n",
        "\n",
        "\n",
        "__Крок 1.__ Обчислити значення $w_{0}+w_{1}x_1 + w_{2}x_2 + ... = \\vec{w}^T\\vec{x}$. (рівняння $\\vec{w}^T\\vec{x} = 0$ задає гіперплощину, яка ділить ознаки на 2 класи);\n",
        "\n",
        "\n",
        "__Крок 2.__ Обчислюємо логарифм відношення шансів: $ \\log(OR_{+}) = \\vec{w}^T\\vec{x}$.\n",
        "\n",
        "\n",
        "__Крок 3.__ Обчислюємо $p_{+}$:\n",
        "\n",
        "$$\\large p_{+} = \\frac{OR_{+}}{1 + OR_{+}} = \\frac{\\exp^{\\vec{w}^T\\vec{x}}}{1 + \\exp^{\\vec{w}^T\\vec{x}}} = \\frac{1}{1 + \\exp^{-\\vec{w}^T\\vec{x}}} = \\sigma(\\vec{w}^T\\vec{x})$$\n",
        "\n",
        "\n",
        "В правій частині отримали сигмоїд-функцію.\n",
        "\n",
        "Логістична регресія прогнозує ймовірність віднесення об'єкту до класу \"+\" як сигмоїд-перетворення лінійної комбінації вектора вагів моделі та вектору ознак об'єкту.\n",
        "\n",
        "$$\\large p_+(x_i) = P\\left(y_i = 1 \\mid \\vec{x_i}, \\vec{w}\\right) = \\sigma(\\vec{w}^T\\vec{x_i}). $$\n",
        "\n",
        "<img\n",
        "src=\"https://ibm.box.com/shared/static/kgv9alcghmjcv97op4d6onkyxevk23b1.png\" width = \"400\" align = \"center\">\n",
        "\n",
        "\n",
        "###__Види логістичної регресії__\n",
        "\n",
        "1. ___Бінарна або біноміальна___\n",
        "> в такій класифікації цільова змінна має два можливих результати: $1$ та $0$. \n",
        "2. ___Поліноміальна___\n",
        "> в такій класифікації цільова змінна може мати 3 та більше можливих невпорядкованих результатів або результат, як категоріальну змінну.\n",
        "3. ___Порядкова регресія___\n",
        "> в такій класифікації цільова змінна може мати 3 та більше можливих впорядкованих результатів, які  мають кількісну інтерпретацію.\n",
        "\n",
        "###__Передумови для логістичної регресії__\n",
        "\n",
        "1. ЛР передбачає, що мультиколінеарність серед незалежних змінних мінімальна або відсутня.\n",
        "\n",
        "2. ЛР передбачає, що незалежні змінні лінійно зв'язані з логарифмом шансів.\n",
        "\n",
        "3. ЛР потребує великого розміру вибірки та правильного прогнозування.\n",
        "\n",
        "4. ЛР передбачає, що спостереження незалежні.\n",
        "\n",
        "### __Переваги методу__\n",
        "\n",
        "1. Модель ЛР не тільки класифікує, а дає ймовірності належності класу.\n",
        "\n",
        "2. ЛР дає не тільки міру того, на скільки релевантний предиктор (розмір коефіцієнту), але і \"напрям\" асоціації (додатній або від'ємний). ЛР простіше реалізувати, інтерпретувати та єфективно навчити.\n",
        "\n",
        "3. ЛР є досить ефективною, коли набір даних має линійно відокремлювані функції.\n",
        "\n",
        "4. В низьковимірному наборі даних, які мають достатню кількість об'єктів для навчання, ЛР не так схильна до перенавчання.\n",
        "\n",
        "### __Недоліки методу__\n",
        "\n",
        "1. ЛР перенавчається на багатовимірних наборах даних.\n",
        "\n",
        "2. Низька якість для нелінійних функцій\n",
        "\n",
        "3. Не в змозі працювати зі складними (комплексними) відношеннями між змінними, та змінними, які слабко пов'язані з цільовою змінною\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUBEZYM2Vi7D"
      },
      "source": [
        "##__Реалізація алгоритму LR__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSxaxbOfQT9K"
      },
      "source": [
        "import pandas as pd\n",
        "import pylab as pl\n",
        "import numpy as np\n",
        "import scipy.optimize as opt\n",
        "from sklearn import preprocessing\n",
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSZnBBBNGHnO"
      },
      "source": [
        "__Завантажимо дані__\n",
        "\n",
        "Дані телекомунікацій для прогнозування відтоку клієнтів. Це  дані про клієнтів, де кожен рядок представляє одного клієнта. Зазвичай утримання клієнтів коштує дешевше, ніж придбання нових, тому фокус цього аналізу - передбачити клієнтів, які залишаться у компанії.\n",
        "\n",
        "Цей набір даних містить інформацію, яка допоможе вам передбачити стратегію для утримання клієнтів. Ви можете проаналізувати всі відповідні дані про клієнтів та розробити цільові програми утримання клієнтів.\n",
        "\n",
        "Набір даних містить інформацію про:\n",
        "\n",
        "* клієнтів, які вибули протягом останнього місяця - Churn;\n",
        "* послуги, якими користується кожен клієнт - телефон, декілька ліній, Інтернет, безпека в Інтернеті, резервне копіювання в режимі онлайн, захист пристроїв, технічна підтримка та потокове телебачення та фільми;\n",
        "* інформація про обліковий запис клієнта - як довго клієнт користується даними послугами, договір, спосіб оплати, електронні рахунки, щомісячні та загальні витрати;\n",
        "* демографічна інформація про клієнтів - стать, вік, а також наявність у них партнерів та утриманців."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fwRvv_3Np1f"
      },
      "source": [
        "path='https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/ChurnData.csv'\n",
        "df_lr = pd.read_csv(path)\n",
        "df_lr.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC8cLnyL6WT3"
      },
      "source": [
        "# Оберемо деякі характеристики для моделі та змінимо тип цільової змінної на цілочисельний\n",
        "df_lr = df_lr[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip',   'callcard', 'wireless','churn']]\n",
        "df_lr['churn'] = df_lr['churn'].astype('int')\n",
        "df_lr.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI1x7i9RDLBi"
      },
      "source": [
        "#Сформуємо масив ознак без цільової змінної\n",
        "X_lr= df_lr[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip']] .values \n",
        "X_lr[0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syxAScvdIRlx"
      },
      "source": [
        "#Сформуємо вектор цільової змінної\n",
        "y_lr = df_lr['churn'].values\n",
        "y_lr[0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiloJ7sdIbzN"
      },
      "source": [
        "#Проведемо стандартизацію даних для кращого представлення даних для алгоритму kNN\n",
        "X_knn = preprocessing.StandardScaler().fit(X_lr).transform(X_lr.astype(float))\n",
        "X_knn[0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeLWiH3iIyXl"
      },
      "source": [
        "# Поділимо вибірку на навчальну та тестову в пропорції 80/20\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_lr_train, X_lr_test, y_lr_train, y_lr_test = train_test_split( X_lr, y_lr, test_size=0.2, random_state=4)\n",
        "print ('Навчальна вибірка:', X_lr_train.shape,  y_lr_train.shape)\n",
        "print ('Тестова вибірка:', X_lr_test.shape,  y_lr_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWDKIy4ASv_P"
      },
      "source": [
        "# Імпортуємо бібліотеку для LR\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfMNkOX_7m_s"
      },
      "source": [
        "###__Параметри `LogisticRegression`__\n",
        "\n",
        "__`solver`:__\n",
        "* `'newton-cg', 'lbfgs', 'liblinear', 'sag', (default ='liblinear')`, – алгоритм, який використовується для задачі оптимізації\n",
        "* для невеликих даних краще використовувати `'liblinear'`,\n",
        "* `'sag'` швидший для великих даних, при цьому  дані повинні бути в одній шкалі\n",
        "* для багатокласових задач використовують `'newton-cg'` та `'lbfgs'`.\n",
        "*`'lbfgs'` та `'newton-cg'` підтримують лише $L_2$-регуляризацію та працюють швидше за `'liblinear'` для деяких даних великої розмірності.\n",
        "\n",
        "__`C`:__\n",
        "\n",
        "`float(default=1.0)`– параметр регуляризації, повинен бути дійсним додатнім. Менше `С` забеспечує сильнішу регуляризацию (контррль від перенавчання)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApZlFZmtS1WP"
      },
      "source": [
        "# Оберемо параметри для LR\n",
        "LR = LogisticRegression(C=0.01, solver='lbfgs').fit(X_lr_train,y_lr_train)\n",
        "LR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9XAkY3WTMJ1"
      },
      "source": [
        "# зробимо прогноз \n",
        "\n",
        "yhat_lr = LR.predict(X_lr_test)\n",
        "yhat_lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeI1B5eZ-x6W"
      },
      "source": [
        ">`predict_proba` повертає оцінки для всіх класів, впорядковані за міткою класів. Перший стовпець - це ймовірність класу $0$, $P(Y = 0 | X)$, а другий стовпець - ймовірність класу $1$, $P (Y = 1 | X)$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh1O2fkq-yaW"
      },
      "source": [
        "yhat_prob = LR.predict_proba(X_lr_test)\n",
        "yhat_prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnyqxuidUtlg"
      },
      "source": [
        "##__Оцінка точності класифікації__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBKbidGnfQwX"
      },
      "source": [
        "###__Матриця невідповідностей (Confusion Matrix)__\n",
        "<center><img src=\"https://2.bp.blogspot.com/-EvSXDotTOwc/XMfeOGZ-CVI/AAAAAAAAEiE/oePFfvhfOQM11dgRn9FkPxlegCXbgOF4QCLcBGAs/s1600/confusionMatrxiUpdated.jpg\" width=\"600\"></img></center>\n",
        "\n",
        "__TP__ - правильно прийнята гіпотеза $H_0$ \n",
        "\n",
        "__TN__ - правильно прийнята гіпотеза $H_1$\n",
        "\n",
        "__FP__ - неправильно знехтувана гіпотеза $H_0$ (Помилка першого роду, $\\alpha$-помилка, рівень значущості)\n",
        "\n",
        "__FN__ - неправильно прийнята гіпотеза $H_0$ (Помилка другого роду, $\\beta$-помилка, рівень значущості, $1-\\beta$ - потужність критерію)\n",
        "\n",
        "__Presision (Влучність)__ - частка правильно спрогнозованих значень. Прогностична значущість позитивного результату\n",
        "\n",
        "$$\\frac{TP}{TP+FP}$$\n",
        "\n",
        "__Recol (Повнота)__ - чутливість\n",
        "\n",
        "$$\\frac{TP}{TP+FN}$$\n",
        "\n",
        "__Sensitivity (Чутливість )__ - частка правильно визначених істино позитивних значень як таких, що мають цей стан \n",
        "\n",
        "$$\\frac{TP}{TP+FN}$$\n",
        "\n",
        "__Specificity (Специфічність)__ - частка правильно визначених істино негативних значень як таких, що не мають цей стан \n",
        "\n",
        "$$\\frac{TN}{TN+FP}$$\n",
        "\n",
        "__Accuracy (Точність)__ - частка правильно спрогнозованих значень\n",
        "$$\\frac{TP+TN}{TP+TN+FP+FN}$$\n",
        "\n",
        "__F1 score__ - міра точності тесту, визначається як середньогармонійне влучності та повноти. $F1\\in[0,1]$, близькість до $1$ означає наближення до ідеальної влучності та повноти.\n",
        "\n",
        "$$F1=2\\cdot\\frac{presision\\cdot recol}{presision + recol}=\\frac{2TP}{2TP+FP+FN}$$ \n",
        "F-міри не беруть до уваги істинно негативних значень для оцінювання продуктивності бінарного класифікатора.\n",
        "\n",
        "__Jaccard index (Міра Жаккара)__ - бінарна міра подібності. \n",
        "\n",
        "Якщо два набори даних мають одні й ті самі елементи, їхній індекс подібності Жаккара дорівнюватиме 1. І навпаки, якщо у них немає спільних елементів, їхня схожість дорівнюватиме 0.\n",
        "\n",
        "$$\\frac{TP}{TP+FP+FN}$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWMFphiOTWfu"
      },
      "source": [
        "# оцінимо точність прогнозу\n",
        "\n",
        "from sklearn import metrics\n",
        "print(\"Точність на навчальних даних: \", metrics.accuracy_score(y_lr_train, LR.predict(X_lr_train)))\n",
        "print(\"Точність на тестових даних: \", metrics.accuracy_score(y_lr_test, yhat_lr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck1S4mRYavf9"
      },
      "source": [
        "# знайдемо матрицю невідповідностей\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "cnf_matrix = confusion_matrix(y_lr_test, yhat_lr)\n",
        "cnf_matrix\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jga6DK9cDX91"
      },
      "source": [
        "class_names=['залишився', 'вибув']\n",
        "# побудуємо діаграму матриці невідповідностей \n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "ConfusionMatrixDisplay.from_estimator(LR, X_lr_test, y_lr_test, display_labels=class_names)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVkcz6e2dUxg"
      },
      "source": [
        "З матриці невідповідностей можна зробити висновок, що \n",
        "\n",
        "* $24$ клієнти, які залишилися, та $4$ клієнти, які розірвали відносини з компанією, було визначено вірно;\n",
        "* прийнято лояльних клієнтів за тих, що вибули - $1$;\n",
        "* врахування абонента, що пішов, за постійного клієнта - $11$\n",
        "\n",
        "___(дана розшифровка може не відповідати матриці при повторному запуску коду, оскільки розбиття виборки робиться випадковим чином)___\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rnvzm-oMZ3V2"
      },
      "source": [
        "# розрахуємо міру F1\n",
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_lr_test, yhat_lr, average='weighted') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FlldMQ6Z_nm"
      },
      "source": [
        "# розрахуємо міру Жаккара\n",
        "from sklearn.metrics import jaccard_score\n",
        "jaccard_score(y_lr_test, yhat_lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q16-BlvTaxKK"
      },
      "source": [
        "# сформуємо звіт показників точності прогнозу\n",
        "print (classification_report(y_lr_test, yhat_lr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0CLqV2G3yxz"
      },
      "source": [
        "##__Метод опорних векторів (SVM - Support Vector Machine)__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27pxOUlpZ6rI"
      },
      "source": [
        "__Метод опорних векторів (SVM)__ - основна ідея методу заключається у відображенні векторів простору ознак, які відображають об'єкти класифікації, в простір більш високої розмірності. Це пов'язано з вищою лінійною відокремленістю в таких просторах. \n",
        "\n",
        "Після переходу в простір більшої розмірності, будується відокремлююча ___гіперплощина (Hyperplane)___. При цьому всі вектори, розташовані по різні боки від цієї гіперплощини будуть відноситися до різних класів.\n",
        "\n",
        "По обидві сторони основної гіперплощини, паралельно їй та на однаковій відстані від неї будуються дві допоміжні гіперплощини, відтань між якими називають ___зазор (Margin)___.\n",
        "\n",
        "Задача постає в побудові гіперплощини таким чином, щоб максимізувати зазор, де не повинно бути векторів.\n",
        "\n",
        "Вважається, що така гіперплощина забезпечує найбільш вдалий поділ на класи та мінімізує середню помилку передбачень.\n",
        "\n",
        "Вектори, які потраплять на границі зазору (тобто будуть лежати на допоміжних гіперплощинах), називають ___опорними векторами (Support Vectors)___\n",
        "\n",
        "\n",
        "<center><img src=\"https://images1.russianblogs.com/22/60/607df9d749c6974c92515f95cb96ca4e.png\" width=\"500\"></img></center>\n",
        "\n",
        "\n",
        "###__Види SVM__\n",
        "\n",
        "1. ___Лінійно роздільний SVM___\n",
        "> навчальні дані є лінійно роздільними, лнійний класифікатор можна навчити максимізуючи жорстку границю (hard-margin SVM).\n",
        "2. ___Лінійний SVM___\n",
        "> навчальні дані не можуть бути лінійно відокремлені, але можуть бути приблизно лінійно відокремлені, тобто будується лінійний класифікатор шляхом максимізації \"м'якого\" запасу.\n",
        "\n",
        "<center><img src=\"https://miro.medium.com/max/1104/1*CD08yESKvYgyM7pJhCnQeQ.png\" width=\"600\"></img></center>\n",
        "\n",
        "3. ___Нелінійний SVM___\n",
        "> навчальні дані лінійно нероздільні, нелінійний класифікатор навчається за допомогою ядрового трюку та м'якої інтервальної максимізації\n",
        "\n",
        "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/1/1b/Kernel_Machine.png\" width=\"500\"></img></center>\n",
        "\n",
        "\n",
        "\n",
        "###__Алгоритм SVM:__\n",
        "\n",
        "Необхідно знайти рівняння гіперплощини $w_1x_1+w_2x_2+...+w_nx_n+w_0=0$ в просторі $\\mathbb{R}$.\n",
        "\n",
        "Загальний вид претворення $F$ об'єкту $x$ в мітку класу $Y$: $F(x) = sign(w^Tx-b)$, де $w = (w_1, w_2, …, w_n), b=-w_0$. Після налаштування вагів алгоритму $w$ та $b$ (навчання), всі об'єкти будуть класифіковані по розташуванню відносно побудованої гіперплощини.\n",
        "\n",
        "Всередині функції $sign()$ міститься лінійна комбінація ознак об'єкту з вагами алгоритму, оскільки SVM відноситься до лінійних алгоритмів. В SVM ваги $w$ та $b$ налаштовуються таким чином, щоб  об'єкти класів лежали якомога далі від гіперплощини, максимізуючи зазор.\n",
        "\n",
        "<center><img src=\"https://hsto.org/r/w1560/webt/n-/5u/gy/n-5ugyyyqejoobj9javfcxaycpk.png\" width=\"400\"></img></center>\n",
        "\n",
        "Для налаштування вагів, мінімізуємо їх норму:\n",
        "\n",
        "$$\\Arrowvert w\\Arrowvert \\rightarrow min$$\n",
        "$$(w^Tw)/2 \\rightarrow min$$\n",
        "\n",
        "Зазором (margin) між об'єктом $x$ та границею класів називається величина $M=y(w^Tx-b)$. Алгоритм допускає помилку на об'єкті тоді, коли $M$ від'ємне (коли $y$ та $(w^Tx-b)$ різних знаків). Якщо  $M \\in (0, 1)$, то об'єкт потрапляє в середину зазору. Если $M > 1$, то об'єкт $x$ класифікується правильно, та знаходиться на деякій відстані від зазору. Тобто:\n",
        "\n",
        "$$y(w^Tx-b) \\geqslant 1$$\n",
        "\n",
        "У випадку ___hard-margin SVM___ маємо:\n",
        "$$ \\left\\{ \\begin{array}{ll} (w^Tw)/2 \\rightarrow min & \\textrm{}\\\\ y(w^Tx-b) \\geqslant 1 & \\textrm{} \\end{array} \\right. $$\n",
        "\n",
        "### __Переваги методу__\n",
        "\n",
        "1. добре працює з простором ознак великої розмірності;\n",
        "2. добре працює з даними невеликого об'єму;\n",
        "3. алгоритм максимізує зазор, який дозволяє зменшити кількість помилок класифікації;\n",
        "4. оскільки алгоритм зведено до задачі квадратичного програмування в опуклій області, то така задача завжди має єдиний розв'язок (розподіляюча гіперплощина з визначеними гіперпараметрами завжди єдина).\n",
        "\n",
        "### __Недоліки методу__\n",
        "\n",
        "1. довгий час навчання алгоритму (для великих наборів даних);\n",
        "2. нестійкість до шумів: викиди в навчальних даних стають опорними об'єктами і впливають на побудову гіперплощини;\n",
        "3. не описані загальні методи побудови ядер та спрямляючих просторів у випадку лінійної неподільності класів.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buzq3-Jszqa5"
      },
      "source": [
        "##__Реалізація алгоритму SVM__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh7jDdxezjuS"
      },
      "source": [
        "#Імпортуємо функцію для svm\n",
        "from sklearn import svm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTZWZ2h20nQa"
      },
      "source": [
        "__Завантажимо дані__\n",
        "Дані є загальнодоступними із бази UCI Machine Learning Repository (Asuncion and Newman, 2007) [http://mlearn.ics.uci.edu/MLRepository.html]. \n",
        "\n",
        "Набір даних складається із записів інформації про клітини людини, кожен з яких містить значення набору характеристик клітин. Поля кожного запису такі:\n",
        "\n",
        "| Назва поля | Опис |\n",
        "| --- | --- |\n",
        "| ID | ідентифікатор|\n",
        "| Clump | Товщина згустка |\n",
        "| UnifSize | Однорвдність розміру клітини |\n",
        "| UnifShape | Однорідність форми клітини |\n",
        "| MargAdh | Гранична адгезія |\n",
        "| SingEpiSize | Розмір одиничної епітеліальної клітини |\n",
        "| BareNuc | Голі ядра |\n",
        "| BlandChrom | М'який хроматин |\n",
        "| NormNucl | Нормальні ядерця |\n",
        "| Мит | Мітози |\n",
        "| Клас | Доброякісні або злоякісні |\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z3FQN_m0mm8"
      },
      "source": [
        "path='https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/cell_samples.csv'\n",
        "df_svm= pd.read_csv(path)\n",
        "df_svm.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3TAHclHmyZz"
      },
      "source": [
        "df_svm.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_K_EIXHPUXY"
      },
      "source": [
        "Поле `ID` містить ідентифікатор пацієнтів. Характеристики зразків клітин містяться в полях від `Clump` до  `Mit`. Значення оцінюються від 1 до 10, де 1 є найбільш близьким показником доброякісної клітини.\n",
        "\n",
        "Поле `Class` містить діагноз, підтверджений медичними процедурами, відносно того, чи є зразки доброякісними (значення = 2) чи злоякісними (значення = 4).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kggcAedaQxF3"
      },
      "source": [
        "# Побудуємо розподілення класів на основі показників `Clump` та `UnifSize`:\n",
        "\n",
        "ax = df_svm[df_svm['Class'] == 4].plot(kind='scatter', x='Clump', y='UnifSize', color='DarkBlue', label='злоякісна');\n",
        "df_svm[df_svm['Class'] == 2].plot(kind='scatter', x='Clump', y='UnifSize', color='Yellow', label='доброякісна', ax=ax);\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MVAuBF5l2om"
      },
      "source": [
        "# за допомогою бібліотеки seaborn побудуємо парні діаграми класів для всих ознак\n",
        "import seaborn as sns\n",
        "sns.pairplot(data=df_svm, hue='Class', palette='Set2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOhP7LAfSDfh"
      },
      "source": [
        "# Розглянемо типи даних\n",
        "df_svm.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BOyeF7vSegA"
      },
      "source": [
        "# `BareNuc` містить  нечислові дані, видалимо ці рядки\n",
        "df_svm = df_svm[pd.to_numeric(df_svm['BareNuc'], errors='coerce').notnull()]\n",
        "df_svm['BareNuc'] = df_svm['BareNuc'].astype('int')\n",
        "df_svm.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4YHe7E72BCs"
      },
      "source": [
        "#Сформуємо масив ознак без цільової змінної\n",
        "X_svm = df_svm[['Clump', 'UnifSize', 'UnifShape', 'MargAdh', 'SingEpiSize', 'BareNuc', 'BlandChrom', 'NormNucl', 'Mit']].values\n",
        "X_svm[0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ngrpHfr4DX9"
      },
      "source": [
        "#Сформуємо множину цільової змінної\n",
        "y_svm =df_svm['Class'].values\n",
        "y_svm[0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdf7jB1t4aNY"
      },
      "source": [
        "# Поділимо вибірку на навчальну та тестову в пропорції 80/20\n",
        "X_svm_train, X_svm_test, y_svm_train, y_svm_test = train_test_split(X_svm, y_svm, test_size=0.2, random_state=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_8VLkq2o8w0"
      },
      "source": [
        "###__Параметри `svm.SVC`__\n",
        "\n",
        "__`kernel`:__\n",
        "\n",
        "_Функція ядра_ - це метод, який використовується для претворення  нелінійних задач в лінійні.\n",
        "* `'rbf'`(по замовчуванню) – Радіальна базисна функція (Radial basis function), Гауссова функція ядра. Простір об'єктів RBF має нескінчену вимірність, що дає можливість збільшувати вимірність для знаходження підходящої гіперплощини\n",
        "* `'linear'` - лінійне ядро\n",
        "* `'poly'` - поліноміальне ядро. Якщо степінь рівна 1, то маємо частинний випадок - лінійне ядро\n",
        "*  `'sigmoid'` - сигмоїдне ядро."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jjIi0yD6VSs"
      },
      "source": [
        "#оберемо параметри моделі для класифікації\n",
        "SVM = svm.SVC(kernel='rbf')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbMGwPAB6fsK"
      },
      "source": [
        "# Навчимо модель\n",
        "SVM.fit(X_svm_train, y_svm_train) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZOCjMYYWn7Hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlVkkVW66nxu"
      },
      "source": [
        "# Зробимо прогноз\n",
        "yhat_svm = SVM.predict(X_svm_test)\n",
        "yhat_svm [0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqlGIOxO6_BU"
      },
      "source": [
        "# оцінимо точність прогнозу\n",
        "\n",
        "print(\"Точність на навчальних даних: \", metrics.accuracy_score(y_svm_train, SVM.predict(X_svm_train)))\n",
        "print(\"Точність на тестових даних: \", metrics.accuracy_score(y_svm_test, yhat_svm))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lo7MvaiiYhiP"
      },
      "source": [
        "# знайдемо матрицю невідповідностей\n",
        "cnf_matrix = confusion_matrix(y_svm_test, yhat_svm)\n",
        "cnf_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fedQIQw3Ytdj"
      },
      "source": [
        "# побудуємо діаграму матриці невідповідностей \n",
        "class_names=['доброякісна', 'злоякісна']\n",
        "ConfusionMatrixDisplay.from_estimator(SVM, X_svm_test, y_svm_test, display_labels=class_names)  \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSJH79RQfzmj"
      },
      "source": [
        "З матриці невідповідностей можна зробити висновок, що \n",
        "\n",
        "* $74$ доброякісних клітини та $58$ злоякісних було класифіковано вірно;\n",
        "* прийнято здорові клітини за уражені - $4$;\n",
        "* не ідентифіковано злоякісну клітину - $1$.\n",
        "\n",
        "___(дана розшифровка може не відповідати матриці при повторному запуску коду, оскільки розбиття виборки робиться випадковим чином)___"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0dArStlY1Eq"
      },
      "source": [
        "# розрахуємо міру F1\n",
        "f1_score(y_svm_test, yhat_svm, average='weighted') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gZO79h0Y8B_"
      },
      "source": [
        "# розрахуємо міру Жаккара\n",
        "jaccard_score(y_svm_test, yhat_svm, pos_label=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw5QXle5YxVd"
      },
      "source": [
        "# сформуємо звіт показників точності прогнозу\n",
        "print (classification_report(y_svm_test, yhat_svm))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEoeTCVzgj0O"
      },
      "source": [
        "##<center>__Самостійні завдання__</center>\n",
        "\n",
        "> Скопіювати блок самостійних завдань в окремий файл ***LastName_CP8.ipynb***\n",
        "\n",
        "> Інсталюйте необхідні пакети бібліотек Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BDe0NyTgmSY"
      },
      "source": [
        "### Завдання №1\n",
        "\n",
        "* Завантажте дані з лінку\n",
        "\n",
        "`url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"`\n",
        "\n",
        "<center><img src=\"http://sebastianraschka.com/images/blog/2015/principal_component_analysis_files/iris.png\" width=\"600\" alt=\"content-vs-colab.png\"></center>\n",
        "\n",
        "* задайте наступні імена колонок датафрейму:\n",
        "\n",
        "`names=['sepal length','sepal width','petal length','petal width','class label']`\n",
        "* виведіть описову статистику датасету\n",
        "* побудуйте парні діаграми класів для всих ознак датасету\n",
        "* сформуйте масив характеристик $X$ та цільової змінної/класу $Y$ \n",
        "* виведіть кількість елементів у кожному класі\n",
        "* поділіть вибірку на навчальну та тестову у співвідношенні 30/70\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0XIjMe_gpOr"
      },
      "source": [
        "# МІСЦЕ ДЛЯ КОДУ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5xD3xxVpvNI"
      },
      "source": [
        "### Завдання №2\n",
        "\n",
        "* Проведіть стандартизацію даних\n",
        "* застосуйте алгоритм LR, використовуючи `solver='liblinear'`,`solver='newton-cg'` та `solver='lbfgs'`\n",
        "* порівняйте результати роботи різних оптимізаторів оціночними критиеріями \n",
        "* побудуйте багатокласову матрицю невідповідностей, та інтерпретуйте її результати\n",
        "* зробіть висновки\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_V_77Igpzgi"
      },
      "source": [
        "# МІСЦЕ ДЛЯ КОДУ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIoUG_3wp8pG"
      },
      "source": [
        "### Завдання №3\n",
        "\n",
        "* Застосуйте алгоритм SVM з ядром `rbf`, `linear` та `sigmoid` \n",
        "* порівняйте результати роботи різних перетворень функцій ядер оціночними критеріями \n",
        "* побудуйте багатокласову матрицю невідповідностей, та інтерпретуйте її результати\n",
        "* зробіть висновки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fB9yio-tp1eu"
      },
      "source": [
        "# МІСЦЕ ДЛЯ КОДУ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFWpAKfmu9nv"
      },
      "source": [
        "### Завдання №4\n",
        "\n",
        "* Порівняйте результати класифікації методами, отриманими в попередньому КП№7, kNN, дерева рішень та LR, SVM для заданого набору даних\n",
        "* оберіть найкращий метод класифікації, обгрунтуйте ваше рішення\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BshPYb59u814"
      },
      "source": [
        "# МІСЦЕ ДЛЯ КОДУ"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}