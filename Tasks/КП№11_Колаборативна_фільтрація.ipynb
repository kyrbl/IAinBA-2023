{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNhBviOWN-YW"
      },
      "source": [
        "<center><font size=\"6\"><b>Комп'ютерний практикум 11.\n",
        "\n",
        "<center><b> Колаборативна фільтрація </font>\n",
        "\n",
        "\n",
        "<center><b><i><font size=\"4\"> Collaborative Filtering\n",
        "\n",
        "\n",
        "\n",
        "</b></center>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWAXRwMSyONP"
      },
      "source": [
        "##__Колаборативна фільтрація__\n",
        "\n",
        ">__Колаборативна фільтрація__ (collaborative filtering) - це метод, який дає автоматичні прогнози, виходячи з накопиченої інформації про інтереси та смаки користувачів.\n",
        "\n",
        "<center><img src=\"https://miro.medium.com/max/3630/1*rCK9VjrPgpHUvSNYw7qcuQ@2x.png\" width=\"700\" alt=\"content-vs-colab.png\" border=\"1\"></center>\n",
        "\n",
        "\n",
        "__Amazon__ почав використовувати підхід на основі колаборативної фільтрації в перші роки існування та домігся підвищення виручки тільки за рахунок алгоритму на 10%. __Netflix__ збільшує кількість контенту, що переглядається, за рахунок підходу на основі алгоритму рекомендаційної системи на 40%. Зараз простіше назвати компанію, яка не використовує подібний підхід, ніж перераховувати всіх, хто використовує. \n",
        "\n",
        "##__Різні парадигми рекомендаційних системх__\n",
        "\n",
        "- **Popularity Based Engine**і - це найпростіший тип рекомендацій. Список трендів, який ви бачите на YouTube або Netflix, базується на цьому алгоритмі. Він відстежує кількість переглядів для кожного фільму/відео, а потім складає список фільмів на основі переглядів у порядку спадання (від найбільшої кількості переглядів до найменшої).\n",
        "\n",
        "- **Content Based Filtering** - пропонує схожі об'єкти на основі певного компонента. Ця система використовує метадані об'єкта, такі як жанр, режисер, опис, актори і т.д. для фільмів, щоб зробити ці рекомендації. Основна ідея цих рекомендаційних систем полягає в тому, що якщо людині сподобався певний фільм, то їй сподобається і схожий на нього.\n",
        "\n",
        "- **Collaborative Filtering** - ця система знаходить людей зі схожими інтересами і надає рекомендації, засновані на цьому зіставленні. Колаборативні фільтри не вимагають метаданих елементів, як їхні аналоги на основі контенту. Існує також два види CF: **model based** та **memory based**.\n",
        "\n",
        "- **Hybrid methods** - Нещодавні дослідження продемонстрували, що гібридний підхід, який поєднує спільну фільтрацію та фільтрацію на основі вмісту, в деяких випадках може бути ефективнішим, ніж чисті підходи. Ці методи також можуть бути використані для подолання деяких поширених проблем у системах рекомендацій, таких як холодний старт і проблема розрідженості.\n",
        "\n",
        "\n",
        "<center><img src=\"https://i.ibb.co/1MXzsPd/content-vs-colab.png\" width=\"600\" alt=\"content-vs-colab.png\" border=\"1\"></center>\n",
        "\n",
        "\n",
        "Клас алгоритмів колаборативної фільтрації поділяється на дві підкатегорії, які зазвичай називають **model based** та **memory based**. Підходи на основі пам'яті безпосередньо працюють зі значеннями записаних взаємодій, не використовуючи моделювання, по суті базуються на пошуку найближчих сусідів (наприклад, знаходять найближчих користувачів до цільового користувача і пропонують найпопулярніші об'єкти від цих сусідів). Підходи на основі моделей допускають наявність базової \"генеративної\" моделі, яка пояснює взаємодію користувача з об'єктом (user-item) для прогнозування вибору нового об'єкта.\n",
        "\n",
        "\n",
        "*Перевага* колаборативних підходів полягає в тому, що вони не потребують інформації про користувачів чи об'єкти, а отже, їх можна використовувати в багатьох ситуаціях. Більше того, чим більше користувачів взаємодіють з об'єктами, тим точнішими стають нові рекомендації: для фіксованого набору користувачів і об'єктів нові взаємодії, зафіксовані з часом, приносять нову інформацію і роблять систему все більш і більш ефективною.\n",
        "\n",
        "Однак, оскільки при створенні рекомендацій враховуються лише минулі взаємодії, колаборативна фільтрація страждає від \"проблеми холодного старту\": неможливо порекомендувати щось новим користувачам або порекомендувати новий об'єкт будь-якому користувачеві, а багато користувачів або об'єктів мають занадто мало взаємодій, щоб ефективно їх обробляти. Цей недолік можна усунути різними способами, використовуючи випадкову стратегію, стратегію максимального очікування, дослідницьку стратегію або, нарешті, використовуючи метод, що не передбачає спільної роботи, на початку життя користувача або об'єкта.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8l9TxG3N2Tzq"
      },
      "source": [
        "##__Memory-Based Collaborative Filtering__\n",
        "Memory-Based Collaborative Filtering підходи можна розділити на дві частини: user-item filtering and item-item filtering.\n",
        "\n",
        "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%205/images/User_Item.png\" width=800px>\n",
        "\n",
        "\n",
        "В _user-item filtering_:\n",
        "\n",
        "Беремо вихідного користувача\n",
        "\n",
        "\n",
        "Знаходимо групу користувачів, максимально схожу на нього (спираючись, наприклад, на оцінки) та дізнаємось, які об'єкти сподобалися цій групі.\n",
        "Вихідному користувачу рекомендуються об'єкти, которые \"подобаються\" знайденій групі користувачів.\n",
        "На вході користувач, на виході – рекомендація об'єктів для даного користувача.\n",
        "\n",
        "В _item-item filtering_:\n",
        "\n",
        "Беремо деякий об'єкт\n",
        "\n",
        "\n",
        "Знаходимо користувачів, яким \"подобається\" цей об'єкт\n",
        "Дивимось на інші об'єкти, які \"подобаються\" знайденим користувачам та виводимо їх в якості рекомендації до вихідного об'єкту\n",
        "На вході об'єкт, на виході– рекомендація у вигляді \"схожих\" об'єктів.\n",
        "\n",
        "_Item-Item Collaborative Filtering_: \"Користувачам, яким \"подобається\" даний об'єкт, може також сподобатися це ...\"\n",
        "\n",
        "_User-Item Collaborative Filtering_: \"Схожим на вас користувачам подобається це ...\"\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##__Model-based Collaborative Filtering__\n",
        "Model-based Collaborative Filtering основана на розкладі матриці  singular value decomposition (SVD, cингулярний розклад). Смисл цього розкладу в тому, що вихідна матриця $\\hat{X}$ розбивається на добуток ортогональних $U, V^T$ та діагональної $S$ матриць.\n",
        "\n",
        "<center><img src=\"https://hackernoon.com/hn-images/1*haUDjEiQmG0RapR0SHos6Q.png\" width=\"600\" alt=\"content-based-formulation-quize.png\"></center> \n",
        "\n",
        "Алгоритми декомпозиції матриць полягають у розкладанні великої та розрідженої матриці взаємодії користувач-об'єкт у добуток двох менших і щільних матриць: **матриці користувач-фактор** (що містить представлення користувачів), яка множиться на **матрицю фактор-об'єкт** (що містить представлення об'єктів).\n",
        "\n",
        "$U$ - **ліва сингулярна матриця**, відображає зв'язок між користувачем та латентними факторами. $S$ - діагональна матриця, що описує силу кожного **латентного фактору**, а транспонована матриця $V$ - **права сингулярна матриця**, що вказує на схожість між об'єктами та латентними офакторами. \n",
        "\n",
        "\"Латентний фактор\" - це широке поняття, яке описує властивість або концепцію, що притаманна користувачеві або об'єкту. Наприклад, для музики латентний фактор може стосуватися жанру, до якого належить музика. SVD зменшує розмірність прогнозованої матриці шляхом вилучення її латентних факторів. По суті, ми відображаємо кожного користувача і кожен товар у латентний простір з розмірністю $r$. Таким чином, це допомагає нам краще зрозуміти взаємозв'язок між користувачами та об'єктами, оскільки вони стають безпосередньо порівнянними. \n",
        "\n",
        "<center><img src=\"https://hackernoon.com/hn-images/1*GUw90kG2ltTd2k_iv3Vo0Q.png\" width=\"600\" alt=\"content-based-formulation-quize.png\" border=\"1\"></center>\n",
        "\n",
        "Основним припущенням матричної декомпозиції є те, що існує досить низьковимірний латентний простір ознак, в якому ми можемо представити як користувачів, так і об'єкти, і що взаємодію між користувачем і об'єктом можна отримати шляхом обчислення скалярного добутку відповідних щільних векторів у цьому просторі.\n",
        "\n",
        "SVD має чудову властивість - мінімальну середньоквадратичну похибку реконструкції (SSE). \n",
        "\n",
        "<center><img src=\"https://miro.medium.com/max/3630/1*E9EE5LXxty1EB8fn_s1jkQ@2x.png\" width=\"600\" alt=\"content-based-formulation-quize.png\" border=\"1\"></center>\n",
        "\n",
        "SVD успішно справляється з проблемою масштабованості та розрідженості, яку створює CF. Однак SVD не позбавлена недоліків. Основний недолік SVD полягає в тому, що ми майже не пояснюємо, чому ми рекомендуємо користувачеві той чи інший об'єкт. Це може стати величезною проблемою, якщо користувачі хочуть знати, чому саме їм рекомендовано той чи інший товар. \n",
        "\n",
        "Цей метод також часто використовується для зменшення розмірності.\n",
        "\n",
        "Методи на основі моделей, які будують латентний простір, зазвичай теоретично мають **більшу похибку, але меншу дисперсію**, ніж методи, що не припускають наявності латентної моделі.\n",
        "\n",
        "Загалом системи рекомендацій важко оцінити: якщо можна використовувати деякі класичні метрики, такі як MSE, accuracy, recall або  precision, слід пам'ятати, що деякі бажані властивості, такі як різноманітність і пояснюваність, не можуть бути оцінені таким чином.\n"
      ],
      "metadata": {
        "id": "f_PmydfLyOmz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Переваги та недоліки колаборативної фільтрації**\n",
        "\n",
        "> **Переваги**\n",
        "* Враховує оцінки інших користувачів\n",
        "* Не потрібно вивчати або витягувати інформацію з рекомендованого товару\n",
        "* Адаптується до інтересів користувача, які можуть змінюватися з часом\n",
        "\n",
        "> **Недоліки**\n",
        "* Функція апроксимації може бути повільною\n",
        "* Може бути невелика кількість користувачів для апроксимації\n",
        "* Проблеми з конфіденційністю при спробі дізнатися про вподобання користувача\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fphMoS_xCcl0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUBEZYM2Vi7D"
      },
      "source": [
        "##__Реалізація алгоритму__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSxaxbOfQT9K"
      },
      "source": [
        "import pandas as pd\n",
        "from math import sqrt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSZnBBBNGHnO"
      },
      "source": [
        "__Завантажимо дані__\n",
        "\n",
        "Набір даних отримано з [GroupLens] (http://grouplens.org/datasets/movielens/). Для завантаження даних скористаємося **`!wget`**,  щоб завантажити їх зі сховища IBM Object Storage.  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<center><img src=\"https://365datascience.com/resources/blog/93ls2rbxxr-how-to-build-a-recommender-system-in-python-1.webp\" width=\"600\"></center>\n"
      ],
      "metadata": {
        "id": "wFgGVBCMHNDr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fwRvv_3Np1f"
      },
      "source": [
        "!wget -O moviedataset.zip https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/moviedataset.zip\n",
        "print('unziping ...')\n",
        "!unzip -o -j moviedataset.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC8cLnyL6WT3"
      },
      "source": [
        "#Зберігаємо інформацію про фільми у фрейм даних \n",
        "movies_df = pd.read_csv('movies.csv')\n",
        "#Зберігаємо інформацію про  користувача у фрейм даних\n",
        "ratings_df = pd.read_csv('ratings.csv')\n",
        "\n",
        "\n",
        "movies_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Видалимо рік зі стовпчика __title__ за допомогою функції заміни і збережемо його у новому стовпчику __year__."
      ],
      "metadata": {
        "id": "xoBfwt8C3kPY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ6y3CtZDEur"
      },
      "source": [
        "#Використовуємо регулярні вирази для пошуку року, що зберігається в дужках\n",
        "#Вказуємо дужки, щоб не конфліктувати з фільмами, які містять рік у назві\n",
        "movies_df['year'] = movies_df.title.str.extract('(\\(\\d\\d\\d\\d\\))',expand=False)\n",
        "#Видаляємо дужки\n",
        "movies_df['year'] = movies_df.year.str.extract('(\\d\\d\\d\\d)',expand=False)\n",
        "#Видалення років зі стовпця 'title'\n",
        "movies_df['title'] = movies_df.title.str.replace('(\\(\\d\\d\\d\\d\\))', '')\n",
        "#Застосовуємо функцію strip, щоб позбутися будь-яких пробілів, які могли з'явитися\n",
        "movies_df['title'] = movies_df['title'].apply(lambda x: x.strip())\n",
        "movies_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Видалимо також стовпчик __\"genres\"__, бо жанри не знадобляться"
      ],
      "metadata": {
        "id": "hfwI8bIK5B7O"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI1x7i9RDLBi"
      },
      "source": [
        "movies_df = movies_df.drop('genres', 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48kQUaqjRst2"
      },
      "source": [
        "Кожен рядок у фреймі даних про рейтинги має ідентифікатор користувача, пов'язаний принаймні з одним фільмом, рейтингом і позначкою часу, яка показує, коли він його переглянув. Нам не знадобиться стовпчик з міткою часу, тому видалимо його, щоб заощадити пам'ять."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mErxVFD3Rst2"
      },
      "outputs": [],
      "source": [
        "ratings_df = ratings_df.drop('timestamp', 1)\n",
        "ratings_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2v_L353Rst3"
      },
      "source": [
        "\n",
        "Почнемо зі створення користувача, якому ми будемо рекомендувати фільми:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LGbw-86Rst3"
      },
      "outputs": [],
      "source": [
        "userInput = [\n",
        "            {'title':'Breakfast Club, The', 'rating':5},\n",
        "            {'title':'Toy Story', 'rating':3.5},\n",
        "            {'title':'Jumanji', 'rating':2},\n",
        "            {'title':\"Pulp Fiction\", 'rating':5},\n",
        "            {'title':'Akira', 'rating':4.5}\n",
        "         ] \n",
        "inputMovies = pd.DataFrame(userInput)\n",
        "inputMovies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtCLQU_HRst4"
      },
      "source": [
        "### **Додавання `movieId` до вхідного користувача**\n",
        "Після створення користувача, витягнемо ідентифікатори вхідних фільмів з фрейму даних фільмів і додамо їх до нього.\n",
        "\n",
        "Це можна зробити спочатку відфільтрувавши рядки, що містять назви вхідних фільмів, а потім об'єднавши цю підмножину з вхідним фреймом даних. Відкинемо непотрібні стовпці для економії місця в пам'яті.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "62ggW5f_Rst4"
      },
      "outputs": [],
      "source": [
        "#Фільтрація фільмів за назвою\n",
        "inputId = movies_df[movies_df['title'].isin(inputMovies['title'].tolist())]\n",
        "#Об'єднання їх, для отримання movieId. Це неявне об'єднання за назвою.\n",
        "inputMovies = pd.merge(inputId, inputMovies)\n",
        "#Видаляємо інформацію, яку ми не будемо використовувати, з вхідного фрейму даних\n",
        "inputMovies = inputMovies.drop('year', 1)\n",
        "#Фінальний вхідний фрейм даних\n",
        "#Якщо фільм, який ви додали вище, не з'явився тут, то його може не бути в оригінальному \n",
        "#dataframe або він може бути написаний по-іншому, будь ласка, перевірте написання з великої літери.\n",
        "inputMovies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F62RUAhZRst5"
      },
      "source": [
        "#### Користувачі, які дивилися ті самі фільми\n",
        "\n",
        "Маючи ідентифікатори фільмів у вхідних даних, ми можемо отримати підмножину користувачів, які дивилися та рецензували фільми з наших вхідних даних."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmegjrnxRst5"
      },
      "outputs": [],
      "source": [
        "#Фільтрування інших користувачів, які переглядали фільми, зі списку цільового користувача та їх зберігання\n",
        "userSubset = ratings_df[ratings_df['movieId'].isin(inputMovies['movieId'].tolist())]\n",
        "userSubset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6RikliIRst6"
      },
      "source": [
        "Згрупуємо рядки за ідентифікатором користувача, використовуючи оператора `Groupby`, який створює декілька підгруп даних, де всі вони мають однакове значення у стовпчику, вказаному як параметр"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrMsQ6yPRst6"
      },
      "outputs": [],
      "source": [
        "userSubsetGroup = userSubset.groupby(['userId'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Наприклад, `userID=1130`."
      ],
      "metadata": {
        "id": "N74Ee6rGn-23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "userSubsetGroup.get_group(1130)"
      ],
      "metadata": {
        "id": "c_kwDEmCoJ0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Відсортуємо ці групи так, щоб користувачі, які мають найбільше спільних фільмів із введеними даними, мали вищий пріоритет. Це забезпечить більш якісні рекомендації, оскільки ми не будемо переглядати кожного користувача окремо."
      ],
      "metadata": {
        "id": "p-AygSAXotL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "userSubsetGroup = sorted(userSubsetGroup,  key=lambda x: len(x[1]), reverse=True)"
      ],
      "metadata": {
        "id": "eeh1CyDjoswA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подивимось на першого користувача."
      ],
      "metadata": {
        "id": "JT4nu3THo_v0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "userSubsetGroup[0:3]"
      ],
      "metadata": {
        "id": "j-SqjHJYpBqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qP-o7IygRst6"
      },
      "source": [
        "### __Подібність користувачів до вхідного(цільового) користувача__\n",
        "\n",
        "Порівняємо користувачів із заданим користувачем і знайдемо найбільш схожого з ним.\n",
        "Міру схожості будемо визначати за допомогою **Коефіцієнта кореляції Пірсона**. Він використовується для вимірювання сили лінійного зв'язку між двома змінними. \n",
        "\n",
        "Формула для знаходження коефіцієнта кореляції Пірсона між множинами $X$ та $Y$ з $N$ значеннями:\n",
        "\n",
        "![alt text](https://wikimedia.org/api/rest_v1/media/math/render/svg/bd1ccc2979b0fd1c1aec96e386f686ae874f9ec0 \"Pearson Correlation\")\n",
        "\n",
        "Кореляція Пірсона є інваріантною до масштабування, тобто множення всіх елементів на ненульову константу або додавання будь-якої константи до всіх елементів. Наприклад, якщо у вас є два вектори $X$ та $Y$, то `pearson(X, Y) == pearson(X, 2 \\* Y + 3)`. Це досить важлива властивість у рекомендаційних системах, тому що, наприклад, два користувачі можуть оцінити два набори об'єктів абсолютно по-різному з точки зору абсолютних оцінок, але вони будуть схожими користувачами (тобто зі схожими ідеями) зі схожими оцінками в різних шкалах .\n",
        "\n",
        "Значення коефіцієнта кореляції варіюються від $r = -1$ до $r = 1$, де $1$ означає в даному контексті, що обидва користувачі мають схожі смаки, а $-1$ означає протилежне.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Виберемо підмножину користувачів для ітерації. Це обмеження накладено тому, що ми не хочемо витрачати надто багато часу на перебір кожного окремого користувача."
      ],
      "metadata": {
        "id": "3ZmmnLQVrr6G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_6gRvc0Rst7"
      },
      "outputs": [],
      "source": [
        "userSubsetGroup = userSubsetGroup[0:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обчислимо кореляцію Пірсона між вхідним користувачем та групою підмножини і збережемо її у словнику, де ключем є ідентифікатор користувача, а значенням - коефіцієнт."
      ],
      "metadata": {
        "id": "mVd_G6F0r916"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSV_mVR9Rst7"
      },
      "outputs": [],
      "source": [
        "#Зберігаємо кореляцію Пірсона у словнику, де ключем є ідентифікатор користувача, а значенням - коефіцієнт\n",
        "pearsonCorrelationDict = {}\n",
        "\n",
        "#Для кожної групи користувачів у нашій підмножині\n",
        "for name, group in userSubsetGroup:\n",
        "    #Почнемо з сортування вхідних даних та поточної групи користувачів, щоб не переплутати значення\n",
        "    group = group.sort_values(by='movieId')\n",
        "    inputMovies = inputMovies.sort_values(by='movieId')\n",
        "    #Отримаємо N для формули\n",
        "    nRatings = len(group)\n",
        "    #Отримаємо оцінки на фільми, які мають спільні риси\n",
        "    temp_df = inputMovies[inputMovies['movieId'].isin(group['movieId'].tolist())]\n",
        "    #Збережемо їх у тимчасовій буферній змінній у форматі списку, щоб полегшити майбутні обчислення\n",
        "    tempRatingList = temp_df['rating'].tolist()\n",
        "    #Виведемо оцінки поточної групи користувачів у вигляді списку\n",
        "    tempGroupList = group['rating'].tolist()\n",
        "    #Обчислимо кореляцію Пірсона між двома користувачами, так званими, x та y\n",
        "    Sxx = sum([i**2 for i in tempRatingList]) - pow(sum(tempRatingList),2)/float(nRatings)\n",
        "    Syy = sum([i**2 for i in tempGroupList]) - pow(sum(tempGroupList),2)/float(nRatings)\n",
        "    Sxy = sum( i*j for i, j in zip(tempRatingList, tempGroupList)) - sum(tempRatingList)*sum(tempGroupList)/float(nRatings)\n",
        "    \n",
        "    #Якщо знаменник відмінний від нуля, то ділимо, інакше кореляція 0.\n",
        "    if Sxx != 0 and Syy != 0:\n",
        "        pearsonCorrelationDict[name] = Sxy/sqrt(Sxx*Syy)\n",
        "    else:\n",
        "        pearsonCorrelationDict[name] = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pearsonCorrelationDict.items()"
      ],
      "metadata": {
        "id": "ii0yjyg8tZUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pearsonDF = pd.DataFrame.from_dict(pearsonCorrelationDict, orient='index')\n",
        "pearsonDF.columns = ['similarityIndex']\n",
        "pearsonDF['userId'] = pearsonDF.index\n",
        "pearsonDF.index = range(len(pearsonDF))\n",
        "pearsonDF.head()"
      ],
      "metadata": {
        "id": "tMAmAIemtci7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-q0jisvRst8"
      },
      "source": [
        "###__Найкращі $x$ користувачів, схожих на вхідного користувача__\n",
        "Тепер знайдемо 50 користувачів, найбільш схожих на вхідного користувача."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topUsers=pearsonDF.sort_values(by='similarityIndex', ascending=False)[0:50]\n",
        "topUsers.head()"
      ],
      "metadata": {
        "id": "FIfkC11ktzeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###__Рекомендація фільмів цільовому користувачу__\n",
        "\n",
        "Візьмемо середньозважене значення рейтингів фільмів, використовуючи кореляцію Пірсона як вагу. Для цього спочатку потрібно отримати фільми, які переглянули користувачі в нашому **pearsonDF** з фрейму даних рейтингів, а потім зберегти їхню кореляцію в новому стовпчику під назвою `similarityIndex`. Це досягається нижче шляхом злиття цих двох таблиць."
      ],
      "metadata": {
        "id": "EI4vh8FZt8Bl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gi5PWtA0Rst8"
      },
      "outputs": [],
      "source": [
        "topUsersRating=topUsers.merge(ratings_df, left_on='userId', right_on='userId', how='inner')\n",
        "topUsersRating.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Помножимо рейтинг фільму на його вагу (індекс схожості), потім підсумуємо нові рейтинги і поділимо їх на суму ваг.\n",
        "\n",
        "Реалізуємо це просто перемноживши два стовпчики, потім згрупувавши фрейм даних за `movieId`, а потім розділивши два стовпчики:\n",
        "\n"
      ],
      "metadata": {
        "id": "mywT7GuFuo-l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPzSTGL8Rst9"
      },
      "outputs": [],
      "source": [
        "topUsersRating['weightedRating'] = topUsersRating['similarityIndex']*topUsersRating['rating']\n",
        "topUsersRating.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Знайдемо суму до topUsers після групування за userId\n",
        "tempTopUsersRating = topUsersRating.groupby('movieId').sum()[['similarityIndex','weightedRating']]\n",
        "tempTopUsersRating.columns = ['sum_similarityIndex','sum_weightedRating']\n",
        "tempTopUsersRating.head()"
      ],
      "metadata": {
        "id": "EIIliJuUvNqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Створюємо порожній фрейм даних\n",
        "recommendation_df = pd.DataFrame()\n",
        "#Тепер беремо середньозважене значення\n",
        "recommendation_df['weighted average recommendation score'] = tempTopUsersRating['sum_weightedRating']/tempTopUsersRating['sum_similarityIndex']\n",
        "recommendation_df['movieId'] = tempTopUsersRating.index\n",
        "recommendation_df.head()"
      ],
      "metadata": {
        "id": "XlTrRAGdvNnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqXOUkXERst9"
      },
      "source": [
        "Відсортуємо і подивимося __ТОП-20__ фільмів, які рекомендував алгоритм!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xm9yFnznRst9"
      },
      "outputs": [],
      "source": [
        "recommendation_df = recommendation_df.sort_values(by='weighted average recommendation score', ascending=False)\n",
        "recommendation_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVuPAwK2Rst-"
      },
      "outputs": [],
      "source": [
        "#Підсумкова таблиця рекомендацій\n",
        "movies_df.loc[movies_df['movieId'].isin(recommendation_df.head(10)['movieId'].tolist())]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEoeTCVzgj0O"
      },
      "source": [
        "##<center>__Самостійні завдання__</center>\n",
        "\n",
        "> Скопіювати блок самостійних завдань в окремий файл ***LastName_CP11.ipynb***\n",
        "\n",
        "> Інсталюйте необхідні пакети бібліотек Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BDe0NyTgmSY"
      },
      "source": [
        "### Завдання №1\n",
        "\n",
        "* Завантажте архів `BX-CSV-Dump.zip` та розпакуйте дані з лінку\n",
        "\n",
        "`url = \"http://www2.informatik.uni-freiburg.de/~cziegler/BX/BX-CSV-Dump.zip\"`\n",
        "\n",
        "* Завантажте датасети `BX-Books.csv` як `df.books` та `BX-Book-Ratings.csv` як `df.ratings`, виведіть частину датасетів на екран\n",
        "\n",
        "Використайте ці дані, щоб побудувати систему рекомендацій, яка підкаже, що користувачеві варто прочитати наступним, виходячи з його поточних книжкових уподобань.\n",
        "\n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0XIjMe_gpOr"
      },
      "source": [
        "# МІСЦЕ ДЛЯ КОДУ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5xD3xxVpvNI"
      },
      "source": [
        "### Завдання №2\n",
        "\n",
        "* Виведіть інформацію про датасет\n",
        "* Залиште в датасеті лише колонки `ISBN`, `Book Title`,`Book Author` and `Publisher`.\n",
        "* Перевірте, чи немає дублікатів назв книг, видаліть, якщо такі є. Для цього скористайтесь функціями `duplicated(subset='Book-Title')`  та `drop_duplicates(subset='Book-Title')`\n",
        "* Об'єднайте імена та прізвища авторів, видаляючи пробіли, щоб система розрізняла авторів з однаковими іменами\n",
        "* Виведіть шапку таблиці, щоб переконатись у об'єднанні\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_V_77Igpzgi"
      },
      "source": [
        "# МІСЦЕ ДЛЯ КОДУ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Завдання №3\n",
        "\n",
        "* Створіть користувача, якому поставте у відповідність 5 довільних кних з переліку та рейтингом (0-10)\n",
        "* Створіть рекомендований список з 10 книг для користувача, спираючись на автора та видавництво.\n"
      ],
      "metadata": {
        "id": "hxpalvUa3BPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# МІСЦЕ ДЛЯ КОДУ"
      ],
      "metadata": {
        "id": "DhRQ-upKS2lV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}