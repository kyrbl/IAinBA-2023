{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "КП№4_Препроцесінг_даних.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNhBviOWN-YW"
      },
      "source": [
        "<center><font size=\"6\"><b>Комп'ютерний практикум 4.\n",
        "\n",
        "Препроцесінг даних</b></font></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-Z8UiiZP9Ya"
      },
      "source": [
        ">Завантажимо бібліотеки та дані"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSxaxbOfQT9K"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fwRvv_3Np1f"
      },
      "source": [
        "path='https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork/labs/Data%20files/automobileEDA.csv'\n",
        "df = pd.read_csv(path)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPYrOLalS-lJ"
      },
      "source": [
        "> Розглянемо інформацію про датасет"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhwQeZdJTEFU"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5sK1KaAuhnx"
      },
      "source": [
        "# розмір датасету\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69x1FVADuzxQ"
      },
      "source": [
        "# кількість унікальних значень для кожного стовпця\n",
        "df.nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A87LhuAHaD8n"
      },
      "source": [
        "##__Описова статистика__\n",
        "\n",
        "Функція `describe` автоматично обчислює базову статистику для всіх неперервних змінних. Будь-які значення `NaN` автоматично пропускаються в цій статистиці.\n",
        "\n",
        "\n",
        "* кількість спостережень\n",
        "* середнє значення\n",
        "* стандартне відхилення (std)\n",
        "* мінімальне значення\n",
        "* IQR (квартилі: 25%, 50%та 75%)\n",
        "* максимальне значення"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMiwPAwKQ2eU"
      },
      "source": [
        "## Попередній візуальний аналіз даних"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wx8IoNNva86d"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqWaCipERPog"
      },
      "source": [
        "pip install seaborn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pLDBqb9SAsV"
      },
      "source": [
        "> імпортуємо бібліотеки `seaborn` для створення статистичної графіки та модуль бібліотеки`matplotlib` `pyplot`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a9QgG7VRnPD"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1IEO1SMS6r2"
      },
      "source": [
        "##__Числові дані__\n",
        "\n",
        "Числові дані представлені типом `int64` або `float64`\n",
        "\n",
        "Для візуалізації числових даних можна використовувати діаграми розсіювання з підігнаними лініями для розуміння лінійного зв'язку між даними.\n",
        "\n",
        "> Можна використовувати функцію `regplot` для побудови діаграми розсіювання та лінійної регресії пакету `seaborn`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUSuxiKoS7i1"
      },
      "source": [
        "# Зв'язок між змінними \"об'єм двигуна\" та \"ціна\"\n",
        "sns.regplot(x=\"engine-size\", y=\"price\", data=df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGjzi6DPWu9f"
      },
      "source": [
        ">Для визначення кореляції між числовими змінними можна використовувати функцію `corr()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NkrMd7JWv2K"
      },
      "source": [
        "# Кореляційна матриця між факторами \"об'єм двигуна\" та \"ціна\" \n",
        "df[[\"engine-size\", \"price\"]].corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVy4LSrcXo7-"
      },
      "source": [
        "##__Категоріальні змінні__\n",
        "Це змінні, які описують \"характеристику\" одиниці даних і вибираються з невеликої групи категорій. \n",
        "\n",
        "Категоріальні змінні можуть мати тип `object` або `int64`. \n",
        "\n",
        ">Візуалізувати категоріальні змінні можна за допомогою діаграми `boxplots` пакету `seaborn` відносно числової (цільової) змінної."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmnmaccGYndA"
      },
      "source": [
        "# трансмісія відносно ціни\n",
        "sns.boxplot(x=\"drive-wheels\", y=\"price\", data=df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fgxlh_GlbNuh"
      },
      "source": [
        "> Якщо включити категоріальні змінні в описову статистику, то можна побачити \n",
        "* кількість спостережень\n",
        "* кількість унікальних записів\n",
        "* значення, яке найчастіше зустрічається\n",
        "* частота такого  значення"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv5CCqv-ceHH"
      },
      "source": [
        "df.describe(include=['object'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLbKmnGWmqj5"
      },
      "source": [
        "> Для підрахунку кількості унікальних значень певного фактору використовують функцію `value_counts`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0bhb2HsnIMM"
      },
      "source": [
        "df['drive-wheels'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuXRTlmPnVWq"
      },
      "source": [
        "> Функція `groupby` групує дані за різними категоріями. Дані групуються на основі однієї або кількох змінних, а аналіз проводиться по окремих групах.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdriSZahntv9"
      },
      "source": [
        "#виділимо три фактора в новий датасет\n",
        "df_group_one = df[['drive-wheels','body-style','price']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDiQIqDlnvF0"
      },
      "source": [
        "# групування по одній категоріальній змінній як середнє числової змінної \n",
        "grouped_test1 = df_group_one.groupby(['drive-wheels'],as_index=False).mean()\n",
        "grouped_test1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOa142dMoEpE"
      },
      "source": [
        "# групування по двом категоріальним змінним як середнє числової змінної \n",
        "grouped_test2 = df_group_one.groupby(['drive-wheels','body-style'],as_index=False).mean()\n",
        "grouped_test2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9La3NhXpm9S"
      },
      "source": [
        "> можна групувати у зведену таблицю, використовуючи функцію `pivot()` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVtZZOLhqI39"
      },
      "source": [
        "#використаємо попереднє групування для зведеної таблиці\n",
        "grouped_pivot = grouped_test2.pivot(index='drive-wheels',columns='body-style')\n",
        "grouped_pivot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mldfJwZWOvO"
      },
      "source": [
        "###__Кодування категоріальних змінних__\n",
        ">Включати в модель якісну змінну типу `object` недоцільно, тому її треба інтерпретувати в \"кількісний\" варіант.\n",
        "Є декілька підходів до кодування категоріальних змінних:\n",
        "\n",
        "1. Співставлення кожній категорії певного числового значення (кодування міток)\n",
        "\n",
        "<center><img src=\"https://miro.medium.com/max/772/1*QQe-4476Oy3_dI1vhb3dDg.png\" width=\"400\"></center>\n",
        "\n",
        "> Таке кодування можливе за допомогою функції `LabelEncoder()` модуля `preprocessing` пакету `sklearn`\n",
        "\n",
        "Проблема такого кодування полягає в тому, що ви створюєте порядок в значеннях фактору, там де його може не бути, виходом є інший варінт кодування:\n",
        "\n",
        "2. Створюються штучні змінні, які відповідають певній категорії, і в результаті ми отримаємо не одне значення-код, а вектор з '0' та '1', що звісно обтяжує модель змінними, але не надає перевагу жодній категорії.\n",
        "\n",
        "Такий вид кодування називають _наївним_ або _dummy-кодуванням_\n",
        "\n",
        "<center><img src=\"https://miro.medium.com/max/3600/1*ggtP4a5YaRx6l09KQaYOnw.png\" width=\"600\"></center>\n",
        "\n",
        "> Даний вид кодування забезпечується функцією `OneHotEncoder()` модуля `preprocessing` пакету `sklearn` або функцією `get_dummies()` пакету `pandas`\n",
        "\n",
        "3. Можна співставляти кожній категорії кількість значень, які вона містить\n",
        "\n",
        "4. Інші способі кодування\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNwFdjfMdOiY"
      },
      "source": [
        "# імпортуємо модуль preprocessing\n",
        "from sklearn import preprocessing "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xf2qFycae7sW"
      },
      "source": [
        "le = preprocessing.LabelEncoder() # обираємо функцію LabelEncoder()\n",
        "le.fit(df['drive-wheels']) # застосовуємо її до категоріального фактору 'drive-wheels'\n",
        "df['drive-wheels']=le.transform(df['drive-wheels']) # заміняємо категоріальні значення на закодовані \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jziT3x9ygQ59"
      },
      "source": [
        "df['drive-wheels']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvmUdUG5uTZ_"
      },
      "source": [
        "> Застосуємо `OneHotEncoder()` до стовпця `'drive-wheels'`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ita7GPKiBL6"
      },
      "source": [
        "df1=df['drive-wheels'] # використаємо закодований на попередньому етапі фактор 'drive-wheels'\n",
        "ohe = preprocessing.OneHotEncoder(sparse=False) # обираємо функцію OneHotEncoder()\n",
        "df1=ohe.fit_transform(df1.values.reshape(-1,1)) # заміняємо значення стовпця на векторні значення "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF4mQ_p1mAZe"
      },
      "source": [
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9opc5o7VzNs8"
      },
      "source": [
        "> Застосуємо `get_dummies()` до фактору `'body-style'`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnEpgVJNyh5u"
      },
      "source": [
        "ohe_dum= pd.get_dummies(df[['body-style']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDxBDBQfynhV"
      },
      "source": [
        "ohe_dum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fY7A_h2muRJv"
      },
      "source": [
        "> Закодуємо категорії стовпця `'body-style'` кількістю їх значень"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-x08sdz3xcHb"
      },
      "source": [
        "df['body-style'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8i2_wBitkns"
      },
      "source": [
        "df2=df['body-style'].map(df.groupby('body-style').size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KbuxzhfxCDU"
      },
      "source": [
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6IzYpiWtwLb"
      },
      "source": [
        "##__Визначення та обробка відсутніх значень (Missing Values)__\n",
        "\n",
        "___Перетворення `?` на `NaN`___\n",
        "\n",
        "для заміни А на В можна використати команду \n",
        " <pre> .replace (A, B, inplace = True) </pre>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xecQZd_YumVv"
      },
      "source": [
        "#NAN значення формуються командою nan пакету numpy\n",
        "df.replace(\"?\", np.nan, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhXZu2t8uymk"
      },
      "source": [
        ">Існує два методи виявлення відсутніх даних:\n",
        "\n",
        "1. <b> .isnull () </b> \n",
        "2. <b> .notnull () </b>\n",
        "\n",
        "На виході отримаємо логічне значення, яке вказує на те, що значення, передане в аргумент, фактично не містить даних."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwTYsoL7tnif"
      },
      "source": [
        "missing_data = df.isnull()\n",
        "missing_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAo0RA9UwIRl"
      },
      "source": [
        "Порахуємо кількість пропущених значень"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YO0O2vzotpo5"
      },
      "source": [
        "for column in missing_data.columns.values.tolist():\n",
        "    print(column)\n",
        "    print (missing_data[column].value_counts())\n",
        "    print(\"\")    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8ch6oUVo2JD"
      },
      "source": [
        "Для візуального відображення пропущених значень можна скористатись функцією `heatmap()` подавши у якості аргументу функцыю визначення пропущених значень `df.isnull()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YThL4B-codps"
      },
      "source": [
        "plt.figure(figsize=(7,6))\n",
        "sns.heatmap(df.isnull(), cbar=False,cmap='viridis')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsqZM6d1wpsN"
      },
      "source": [
        "##__Усунення пропущених даних__\n",
        "\n",
        "  1. Видалити дані <br>\n",
        "        а. Видалити весь рядок <br>\n",
        "        b. Видалити весь стовпець (стовпчик незначний для моделі, або містить 50% і білше пропущених значень)\n",
        "  2. Замінити дані <br>\n",
        "        а. Замінити на середнє,максимальне, мінімальне (для числових значень) <br>\n",
        "        b. Замінити на найчастіш вживане (для категоріальних даних) <br>\n",
        "        c. Замінити іншою функцією"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IUq9tl0yFDs"
      },
      "source": [
        "# Обчислимо середнє для фактору \"stroke\"\n",
        "avg_stroke=df['stroke'].astype('float').mean(axis=0)\n",
        "print(\"Середнє для stroke:\", avg_stroke)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XclOCGb70HCi"
      },
      "source": [
        "# Замінимо NaN у факторі \"stroke\" на середнє \n",
        "df[\"stroke\"].replace(np.nan, avg_stroke, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y1tbDB70rD9"
      },
      "source": [
        "# Перевіримо наявність пропущених значень в даному факторі\n",
        "missing_data = df.isnull()\n",
        "print (missing_data[\"stroke\"].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC4_Knju1zNs"
      },
      "source": [
        "> якщо необхідно видалити рядок з NaN використовують команду\n",
        "`dropna()`\n",
        "\n",
        "> після цього краще \"перезавантажити\" індекси для коректного відтворення датасету за допомогою команди `reset_index(drop=True, inplace=True)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THn-04BB1Atz"
      },
      "source": [
        "# видалимо ряжок з  NaN в стовбчику  \"horsepower-binned\" \n",
        "df.dropna(subset=[\"horsepower-binned\"], axis=0, inplace=True)\n",
        "\n",
        "# перезапишемо індекси, оскільки було одне видалення \n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HcVze6P0rCq"
      },
      "source": [
        "# Перевіримо наявність пропущених значень в даному факторі\n",
        "missing_data = df.isnull()\n",
        "print (missing_data[\"horsepower-binned\"].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mM5J1Iy3WhF"
      },
      "source": [
        "##__Групуванн даних (Binning)__ \n",
        "> __Бінінг__ - це процес перетворення числових даних у категоріальні. Зручний для числових значень широкого діапазону. Вихідні значення даних, які потрапляють у заданий невеликий проміжок - бін, замінюються значенням, що є представником цього інтервалу, часто центральним значенням.\n",
        "Виділяють:\n",
        "\n",
        "* Групування з фіксованою шириною бінів\n",
        "* Квантильне групування\n",
        "* Інстинктивне групування \n",
        "\n",
        "> Групування можна здійснювати вручну, або за допомогою функції `LKBinsDiscretizer()` модуля `preprocessing` пакету `sklearn`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2geC4a_U_fZn"
      },
      "source": [
        "from sklearn.preprocessing import KBinsDiscretizer  # імпортуємо функцію\n",
        "est = KBinsDiscretizer(n_bins = 5, encode = 'ordinal', strategy='quantile') # розіб'ємо на 5 груп квантильним підходом\n",
        "df['price_code'] = est.fit_transform(np.array(df['price']).reshape(-1,1)) # створимо нову колонку з відповідним кодуванням в датасеті\n",
        "df[['price','price_code']] #вивидемо оригінальний та перетворений стовпець\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LV5ZV6VjHHqy"
      },
      "source": [
        "## __Нормалізація та Стандартизація даних__\n",
        "\n",
        "> __Нормалізація даних__ - це зміна значень числових стовпців у наборі даних до загальної шкали (певного інтервалу значень), без спотворення відмінностей у діапазонах значень. \n",
        "\n",
        "> __Стандартизація даних__ передбачає таке пертворення даних, що призводить до нормального розподілу\n",
        "\n",
        "Часто використовують таке масштабування даних:\n",
        "* MinMax\n",
        "$$ X_iscal = \\frac{X_i - min(X)}{max(X) - min(X)} $$\n",
        "* Standart Scaler\n",
        "$$ X_iscal = \\frac{X_i - mean(X)}{std(X)} $$\n",
        "* Max\n",
        "$$ X_iscal = \\frac{X_i}{max(X)} $$\n",
        "* $L_1$ norm\n",
        "$$ X_iscal = \\frac{X_i}{\\sum_{i=1}^{m}X_i} $$\n",
        "* $L_2$ norm (Euclidean norm)\n",
        "$$ X_iscal = \\frac{X_i}{\\sqrt{\\sum_{i=1}^{m}X_i^2}} $$\n",
        "\n",
        ">Для MinMax-ного масштабування, яке перетворює числові дані в проміжок $[0, 1]$, можна використовувати функцію `MinMaxScaler()` модуля `preprocessing` пакету `sklearn`\n",
        "\n",
        "> Для стандартизації можна використовувати функцію  `StandardScaler()`модуля `preprocessing` пакету `sklearn`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yanS64qWR-c7"
      },
      "source": [
        "Виділимо новий датасет із вихідного з певними числовими факторами"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y-qW29KLGvv"
      },
      "source": [
        "  new_df=df[['wheel-base','length','width','height']]         \n",
        "  new_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZsFpte8tvxk"
      },
      "source": [
        "# MimMax-масштабування\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "MMS = MinMaxScaler()\n",
        "new_df1 = MMS.fit_transform(new_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eTfGZNrL1A4"
      },
      "source": [
        "# перетворюємо отриманий масив у фрейм\n",
        "new_df_mms=pd.DataFrame({'wheel-base':new_df1[:,0],'length':new_df1[:,1],'width':new_df1[:,2],'height':new_df1[:,3]})\n",
        "new_df_mms.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Etwb9RKdSrzF"
      },
      "source": [
        "new_df_mms.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d68PkF69RGgv"
      },
      "source": [
        "# Стандартизація даних \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "SS = StandardScaler()\n",
        "new_df1 = SS.fit_transform(new_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTq3eoTsRchn"
      },
      "source": [
        "# перетворюємо отриманий масив у фрейм\n",
        "new_df_ss=pd.DataFrame({'wheel-base':new_df1[:,0],'length':new_df1[:,1],'width':new_df1[:,2],'height':new_df1[:,3]})\n",
        "new_df_ss.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrSFeSFFSz4y"
      },
      "source": [
        "new_df_ss.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0xZilE1TFpg"
      },
      "source": [
        "##<center>__Самостійні завдання__</center>\n",
        "\n",
        "> Скопіювати блок самостійних завдань в окремий файл ***LastName_CP4.ipynb***\n",
        "\n",
        "> Інсталюйте необхідні пакети бібліотек Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2DcwcrSULJA"
      },
      "source": [
        "### Завдання №1\n",
        "\n",
        "Завантажте дані з ресурсу\n",
        "\n",
        "URL = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U43QSaHHTFOL"
      },
      "source": [
        "# МІСЦЕ ДЛЯ КОДУ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNIV6q91UW2B"
      },
      "source": [
        "### Завдання №2\n",
        "\n",
        "* Виведіть інформацію про датасет, описову статистику для кількісних змінних та для якісних змінних\n",
        "\n",
        "* побудуйте графік регресії для змінних `Survived` та `Pclass`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfweeG1YVU_h"
      },
      "source": [
        "# МІСЦЕ ДЛЯ КОДУ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpjg_1PvVTua"
      },
      "source": [
        "### Завдання №3\n",
        "\n",
        "* побудуйте `heatmap()` для візуального відображення пропущених значень\n",
        "* для кількісної змінної поповніть пропущені дані середнім значенням\n",
        "* для категоріальної змінної поповніть пропущені значення значенням, яке зустрічається найчастіше"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeNvNJdpWN7d"
      },
      "source": [
        "# МІСЦЕ ДЛЯ КОДУ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEqKagJ3WRjS"
      },
      "source": [
        "### Завдання №4\n",
        "\n",
        "Оберіть 4 категоріальних змінних та закодуйте:\n",
        "* Змінну_1 -  за допомогою функції `LabelEncoder()`\n",
        "* Змінну_2 -  за допомогою функції `get_dummies()`\n",
        "* Змінну_3 -  за допомогою функції `OneHotEncoder()`\n",
        "* Змінну_4 -  кількістю значень відповідної категорії\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2rVl_4fWSgJ"
      },
      "source": [
        "# МІСЦЕ ДЛЯ КОДУ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmjUBu_FXqa0"
      },
      "source": [
        "### Завдання №5\n",
        "Поділіть на 4 вікові групи змінну `Age`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwjTreWwWUcm"
      },
      "source": [
        "# МІСЦЕ ДЛЯ КОДУ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0GsLKbqYSpL"
      },
      "source": [
        "### Завдання №6\n",
        "\n",
        "* Створіть новий датафрейм з вихідного тільки із числових значень\n",
        "* Застосуйте $MinMax$-Нормування даних та збережіть в новий датафрейм, виведіть описову статистику\n",
        "* Застосуйте $Standart Scaling$ даних та збережіть в новий датафрейм, виведіть описову статистику\n",
        "* Застосуйте $L_1$-Нормування та збережіть в новий датафрейм, виведіть описову статистику\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F25Xs8GXWWsq"
      },
      "source": [
        "# МІСЦЕ ДЛЯ КОДУ"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}