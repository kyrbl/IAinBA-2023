{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNhBviOWN-YW"
      },
      "source": [
        "<center><font size=\"6\"><b>Комп'ютерний практикум 5.\n",
        "\n",
        "<center><b> Методи кластеризації </font>\n",
        "\n",
        "\n",
        "<center><b><i><font size=\"4\"> KM (K Means Algorithm)\n",
        "\n",
        "\n",
        "\n",
        "</b></center>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWAXRwMSyONP"
      },
      "source": [
        "##__Навчання без вчителя (Unsupervised learning)__\n",
        "\n",
        ">__Навчання без вчителя (Unsupervised learning)__ - це напрямок машинного навчання, що об'єднує алгоритми і методи побудови моделей на основі опису множини об'єктів (навчальної вибірки) та необхідності знайти внутрішні взаємозв'язки, залежності, закономірності, що існують між об'єктами.\n",
        "\n",
        "> В алгоритмах навчання без вчителя помилка моделі на множині для навчання не обраховується. Замість помилки використовується інформація про поточний стан параметрів моделі та прикладів навчальної множини.\n",
        "\n",
        "<center><img src=\"https://hsto.org/getpro/habr/post_images/bfa/292/267/bfa2922674222578915fd86afecfe1dd.jpg\" width=\"600\"></center>\n",
        "\n",
        "__Типи вхідних даних__\n",
        "\n",
        "* _<u>Опис об'єктів за ознаками.</u>_ Кожен об'єкт описується набором своїх характеристик - ознаками, які можуть бути числовими або категоріальними.\n",
        "\n",
        "* _<u>Матриця відстаней між об'єктами.</u>_ Кожен об'єкт описується відстанню до інших об'єктів навчальної вибірки.\n",
        "\n",
        "__Типи задач__\n",
        "* Кластеризація\n",
        "* Пошук асоціативних правил\n",
        "* Поповнення пропущених значень\n",
        "* Скорочення розмірності\n",
        "* Візуалізація даних\n",
        "\n",
        ">___Задачі кластеризації___\n",
        "\n",
        "<center><img src=\"https://i.vas3k.ru/7qz.jpg\" width=\"400\"></center>\n",
        "\n",
        "Вибірка об'єктів розбивається на неперетинні підмножини - кластери за схожістю об'єктів в одному кластрі. Вихідна інформація подається у вигляді матриці відстаней.\n",
        "\n",
        "__Методи кластеризації__\n",
        "* Графові алгоритми \n",
        "* Статистичні алгоритми\n",
        "* Ієрархічні алгоритми\n",
        "* Нейронна мережа Кохонена\n",
        "\n",
        "\n",
        ">___Задачі пошуку правил асоціації___\n",
        "\n",
        "<center><img src=\"https://mksaad.files.wordpress.com/2019/07/7r1.jpg\" width=\"400\"></center>\n",
        "\n",
        "Вихідна інформація подається у вигляді опису характеристик об'єктів. Необхідно знайти такі набори ознак і такі значення цих ознак, які досить часто (невипадково) зустрічаються в описі характеристик об'єктів. \n",
        "\n",
        "__Методи__\n",
        "* Аналіз ринкових кошиків\n",
        "* Apriori\n",
        "\n",
        ">___Задача поповнення пропущених даних___\n",
        "\n",
        "<center><img src=\"https://thepracticaldev.s3.amazonaws.com/i/egr5hnuazl4rz5mi4llw.jpg\" width=\"400\"></center>\n",
        "\n",
        "\n",
        "Вихідна інформація подається у вигляді опису характеристик об'єктів. Значення деяких характеристик можуть бути відсутніми. Для поповнення таких значень вважають даний об'єкт цільовим, будують алгоритм, який прогнозує його значення в залежності від інших ознак. Пропущені значення заповнюють прогнозами. \n",
        "\n",
        "__Методи__\n",
        "\n",
        "Якщо ознака кількісна, застосовується регресійний аналіз, якщо категоріальна - методи класифікації.\n",
        "\n",
        ">___Задачі скорочення розмірності___\n",
        "\n",
        "<center><img src=\"https://miro.medium.com/max/1192/1*vXQ5sgMF0XmiY4Jc6gJVwA.png\" width=\"600\"></center>\n",
        "\n",
        "Вихідна інформація подається у вигляді опису характеристик об'єктів, причому число ознак (факторів) може бути достатньо великим. Задача полягая у відображенні цих даних в простір меншої розмірності з мінімальною втратою інформації.\n",
        "\n",
        "__Методы__\n",
        "* Метод головних компонент (PCA)\n",
        "* Метод незалежних компонент\n",
        "* Лінійний дискримінантний аналіз (LDA)\n",
        "\n",
        ">___Задачі візуалізації даних___\n",
        "\n",
        "<center><img src=\"https://thumbs.dreamstime.com/z/abstract-d-big-data-visualization-concept-clustering-infographics-design-cluster-analysis-vector-illustration-188989840.jpg\" width=\"300\"></center>\n",
        "\n",
        "\n",
        "Деякі методи кластеризації та пониження розмірності будують представлення вибірки в просторі розмірності два, що дозволяє відображати багатовимірні дані у вигляді плоских графіків та аналізувати їх візуально, що покращує розуміння суті задачі.\n",
        "\n",
        "__Методи__\n",
        "\n",
        "* Дендрограма\n",
        "* Карта Кохонена\n",
        "* Карта схожості\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8l9TxG3N2Tzq"
      },
      "source": [
        "##__Задачі кластеризації__\n",
        "\n",
        "<center><img src=\"https://www.tutorialandexample.com/wp-content/uploads/2019/11/An-example-of-a-cluster-system.png\" width=\"600\"></center>\n",
        "\n",
        "Задача кластеризації в машинному навчанні — це задача розбиття множини об'єктів на групи за схожими характеристиками. На відміну від класифікації перелік груп не вказаний і визначається в процесі роботи алгоритму.\n",
        "\n",
        ">__Етапи кластеризації__\n",
        "\n",
        "* Відбір даних\n",
        "* Визначення множини змінних, по яким будуть оцінюватися об'єкти у виборці\n",
        "* Обчислення міри схожості між об'єктами\n",
        "* Застосування методів кластерного аналізу для створення групп схожих об'єктів\n",
        "\n",
        "Після отримання та аналізу результатів можливе коригування обраної метрики та методу кластеризації до отримання оптимального результату.\n",
        "\n",
        "\n",
        ">__Метрика (відстань)__\n",
        "\n",
        "* __Евклідова метрика__\n",
        "$$\\rho(x, y)=\\sqrt{\\sum_{i=1}^n{(x_i-y_i)^2}} $$\n",
        "\n",
        "* __Манхеттенська метрика ($L_1$)__\n",
        "$$\\rho(x, y)=\\sum_{i=1}^n{|x_i-y_i|} $$\n",
        "Міра впливу викидів менша в порівнянні з Евклідовою метрикою\n",
        "* __Метрика Мінковського__\n",
        "$$\\rho(x, y)=\\left(\\sum_{i=1}^n{|x_i-y_i|^q} \\right)^{1/q}$$\n",
        "Застосовується у випадку, коли необхідно збільшити або зменшити вагу, яка відноситься до розмірності, для якої відповідні об'єкти сильно відрізняються \n",
        "\n",
        "$q=1$ - Манхетенська метрика\n",
        "\n",
        "$q=2$ - Евклідова метрика\n",
        "\n",
        "* __Метрика Чебишева__\n",
        "$$\\rho(x, y)=\\max\\left(|x_i-y_i|\\right)$$\n",
        "Корисна, коли необхідно визначити два об'єкти як \"різні\", якщо вони відрізняються координатою\n",
        "\n",
        ">__Класифікація алгоритмів__\n",
        "\n",
        "* _<u>Ієрархічні алгоритми (алгоритми таксономії)</u>_ будують систему вкладених розбиттів. На виході отримується дерево кластерів, де корінь - вся вибірка, а листя - найменші кластери\n",
        "* _<u>Плоскі алгоритми</u>_ будують одне розбиття об'єктів на кластери.\n",
        "* _<u>Чіткі (неперетинні) алгоритми_</u> кожному об'єкту вибірки ставлять у відповідність номер кластеру, тобто кожен об'єкт належить лише одному кластеру.\n",
        "* _<u>Нечіеткі (перетинні) алгоритми_</u> кожному об'єкту ставлять у відповідність набір дійсних чисел, які показують степінь (ймовірність) відношення об'єкту до кластерів.\n",
        "\n",
        "### __Застосування кластеризації__\n",
        ">___Медицина___\n",
        "\n",
        "__Візуалізація__. На скануванні кластерний аналіз можна використовувати для розрізнення різних типів тканин на тривимірному зображенні для багатьох різних цілей.\n",
        "\n",
        "__Аналіз антимікробної активності.__ Кластерний аналіз можна використовувати для аналізу закономірностей резистентності до антибіотиків, для класифікації антимікробних сполук за механізмом їх дії, для класифікації антибіотиків за їх антибактеріальною активністю.\n",
        "\n",
        "__Сегментація IMRT.__ Кластеризація може бути використана для поділу зображення на окремі зони для аналізу в радіаційній терапії.\n",
        "\n",
        ">___Бізнес і маркетинг___\n",
        "\n",
        "__Маркетингове дослідження.__ Кластерний аналіз широко використовується в маркетингових дослідженнях при роботі з багатоваріантними даними опитувань і тестових панелей. Дослідники ринку використовують кластерний аналіз для поділу загальної сукупності споживачів на сегменти ринку та для кращого розуміння відносин між різними групами споживачів/потенційних клієнтів, а також для сегментації ринку, позиціонування продукту, розробки нових продуктів та вибору тестових ринків.\n",
        "\n",
        "__Групування товарів для покупок.__ Кластеризація може бути використана для групування всіх товарів, доступних в Інтернеті, в набір унікальних продуктів. Наприклад, усі товари на eBay можна згрупувати в унікальні продукти.\n",
        "\n",
        ">___Суспільні науки___\n",
        "\n",
        "__Аналіз злочинності.__ Кластерний аналіз може бути використаний для виявлення областей, де є більші випадки окремих видів злочинів. Визначивши ці окремі зони або «гарячі точки», де подібний злочин стався протягом певного періоду часу, можна ефективніше керувати ресурсами правоохоронних органів.\n",
        "\n",
        "__Навчальний аналіз даних.__ Кластерний аналіз використовується, наприклад, для визначення груп шкіл або учнів зі схожими характеристиками.\n",
        "\n",
        "__Типології.__ На основі даних опитувань такі проекти, як ті, що здійснюються дослідницьким центром Pew Research Center, використовують кластерний аналіз для визначення типологій думок, звичок і демографії, які можуть бути корисними в політиці та маркетингу."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtM5UAzB8LpF"
      },
      "source": [
        "##__Метод $k$-середніх ($k$-means)__\n",
        "\n",
        "Метод $k$-средних (k-means) — найбільш вживаний метод кластеризации. Полягає в мінімізації сумарного квадрату відхилення точок кластеру від центроїдів цього кластеру (**inertia**).\n",
        "$$g$$\n",
        "$$V=\\sum_{i=1}^{k}\\sum_{x \\in S_{i}} (x-\\mu_{i})^{2}$$\n",
        "\n",
        "де $k$ — число кластерів, $S_{i}$ — отримані кластери, $i=1,2,\\dots ,k$, а $\\mu _{i}$ — центри мас усіх векторів $x$ з кластеру $S_{i}$.\n",
        "\n",
        "Інерцію можна розпізнати як міру внутрішньої когерентності кластерів. Вона має недоліки:\n",
        "\n",
        "* є припущення, що кластери є опуклими та ізотропними, що не завжди так.Погано реагує на подовжені скупчення або різноманіття неправильної форми.\n",
        "\n",
        "* не є нормалізованим показником: ми просто знаємо, що нижчі значення краще, а нуль оптимальний. Але в багатовимірних просторах евклідові відстані мають тенденцію до збільшення (це приклад так званого «прокляття розмірності»). Виконання алгоритму зменшення розмірності, такого як аналіз головних компонентів (PCA) перед кластеризацією k-середніх, може полегшити цю проблему та прискорити обчислення.\n",
        "\n",
        "<center><img src=\"https://miro.medium.com/max/720/1*KrcZK0xYgTa4qFrVr0fO2w.gif\" width=\"400\"></center>\n",
        "\n",
        "###__Етапи алгоритму:__\n",
        "1. Початкова ініціалізація центроїдів кластерів будь-яким способом (наприклад, можна задати початкові значення випадково обраними точками з простору даних; можна обрати випадкові точки з вхідного масиву даних і т.д.).\n",
        "2. Відбувається ассоціація між елементами даних та кластерами, представлених своїми центроїдами.\n",
        "3. Відбувається перерозподіл центроїдів, як среднє значення від даних, які були включені у відповідний кластер (відбувається модифікація параметрів моделі таким чином, щоб максимізувати ймовірність потрапляння елементу в обраний кластер). У випадку, якщо кластер після кроку 2 виявився порожнім, то відбувається переініціалізація іншим способом.\n",
        "\n",
        "Кроки 2-3 повторються до збіжності, або доки не буде досягнуто іншого критерію зупинки алгоритму.\n",
        "\n",
        "\n",
        "### __Переваги методу__\n",
        "\n",
        "1. Простий у реалізації\n",
        "2. Достатньо швидкий\n",
        "3. Має лінійну складність $O(n)$\n",
        "4. Добре працює, коли кластери приблизно однакового розміру та регулярної опуклої форми\n",
        "\n",
        "\n",
        "### __Недоліки методу__\n",
        "\n",
        "1 Не гарантується досягнення глобального мінімуму сумарного квадрату відхилення $V$, а лише одного з локальних мінімумів.\n",
        "2. Результат залежить від вибору вихідних центроїдів та метрики, не існує методу оптимального вибору центроїдів.\n",
        "3. Кількість кластерів необхідно знати наперед.\n",
        "4. Не справляється з випадком, коли об'єкт належить різним кластерам в рівній мірі обо не належить жодному кластеру.\n",
        "5. Погано кластеризує дані з різною щільністю або кластери неопуклої форми\n",
        "\n",
        "<center><img src=\"https://miro.medium.com/max/536/1*Xvl-pXxsLAZ7gbTUuvgMtA.png\" width=\"400\"></center>\n",
        "\n",
        "<img src=\"https://arogozhnikov.github.io/images/opera/post/clustering-kmeans-smiley.gif\" width=\"600\" >\n",
        "</center>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUBEZYM2Vi7D"
      },
      "source": [
        "##__Реалізація алгоритму k-means__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSxaxbOfQT9K"
      },
      "source": [
        "import random \n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.cluster import KMeans \n",
        "#from sklearn.datasets.samples_generator import make_blobs \n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSZnBBBNGHnO"
      },
      "source": [
        "__Завантажимо дані__\n",
        "\n",
        "Нехай є набір даних клієнтів, потрібно застосувати сегментацію клієнтів до цих історичних даних. Сегментація клієнтів — це практика поділу клієнтської бази на групи осіб, які мають схожі характеристики. Бізнес може орієнтуватися на ці конкретні групи клієнтів і ефективно розподіляти маркетингові ресурси. Наприклад, одна група може містити клієнтів, які мають високий прибуток і низький ризик, тобто з більшою ймовірністю куплять продукти або передплатять послугу. Завдання бізнесу – утримати цих клієнтів. Інша група може включати клієнтів з неприбуткових організацій. І так далі.\n",
        "\n",
        "Завантажимо набір даних."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fwRvv_3Np1f"
      },
      "source": [
        "path='https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/Cust_Segmentation.csv'\n",
        "cust_df = pd.read_csv(path)\n",
        "cust_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILTN9nEezMZF"
      },
      "source": [
        "###__Препроцесінг__\n",
        "\n",
        "Ознака \"Адреса\" в цьому наборі даних є категоріальною змінною. Алгоритм k-means не застосовується безпосередньо до категоріальних змінних, оскільки функція евклідової відстані не працює на таких типах даних. Видалимо цей фактор з набору даних."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC8cLnyL6WT3"
      },
      "source": [
        "df = cust_df.drop('Address', axis=1)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ6y3CtZDEur"
      },
      "source": [
        "#Нормалізуємо дані \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "X = df.values[:,1:]\n",
        "X = np.nan_to_num(X)\n",
        "Clus_dataSet = StandardScaler().fit_transform(X)\n",
        "Clus_dataSet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl33lO9F26Sv"
      },
      "source": [
        "###__Моделювання__\n",
        "\n",
        "Клас `KMeans` має багато параметрів, які можна використовувати, але ми будемо використовувати ці три:\n",
        "* `init` метод ініціалізації центроїдів.\n",
        "    * Значення буде: `k-means++`, оскільки вибирає початкові центри кластерів для k-середнього кластеризації розумним способом, щоб прискорити зближення.\n",
        "* `n\\_clusters`: кількість кластерів, а також кількість центроїдів.\n",
        "    * Значення буде: 3 (оскільки у нас 3 центри).\n",
        "* `n\\_init`: кількість часу, протягом якого алгоритм k-середніх буде запущено з різними початковими центроїдами. Кінцеві результати будуть найкращим результатом `n\\_init` послідовних запусків з точки зору інерції. </li>\n",
        "    * Значення буде: 12\n",
        "\n",
        "Ініціалізуйте KMeans цими параметрами, де вихідний параметр називається <b>k_means</b>.\n",
        "\n",
        "Збережимо мітки для кожної точки в моделі за допомогою атрибута `.labels_ KMeans`  як labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI1x7i9RDLBi"
      },
      "source": [
        "# Реалізація\n",
        "clusterNum = 3\n",
        "k_means = KMeans(init = \"k-means++\", n_clusters = clusterNum, n_init = 12)\n",
        "k_means.fit(X)\n",
        "labels = k_means.labels_\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "169XI2S9DNjx"
      },
      "source": [
        "# дістанемо координати центроїдів \n",
        "k_means_cluster_centers = k_means.cluster_centers_\n",
        "k_means_cluster_centers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syxAScvdIRlx"
      },
      "source": [
        "#Призначимо мітки кожному рядку у фреймі даних\n",
        "df[\"Clus_km\"] = labels\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiloJ7sdIbzN"
      },
      "source": [
        "#Перевіримо значення центроїдів, усереднюючи характеристики в кожному кластері\n",
        "df.groupby('Clus_km').mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeLWiH3iIyXl"
      },
      "source": [
        "# Подивимося на розподіл клієнтів за їх віком і доходом:Поділимо вибірку на навчальну та тестову в пропорції 80/20\n",
        "\n",
        "area = np.pi * ( X[:, 1])**2  \n",
        "plt.scatter(X[:, 0], X[:, 3], s=area, c=labels.astype(np.float), alpha=0.5)\n",
        "plt.xlabel('Age', fontsize=18)\n",
        "plt.ylabel('Income', fontsize=16)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWDKIy4ASv_P"
      },
      "source": [
        "# Імпортуємо бібліотеку для KNN\n",
        "from mpl_toolkits.mplot3d import Axes3D \n",
        "fig = plt.figure(1, figsize=(8, 6))\n",
        "plt.clf()\n",
        "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
        "\n",
        "plt.cla()\n",
        "# plt.ylabel('Age', fontsize=18)\n",
        "# plt.xlabel('Income', fontsize=16)\n",
        "# plt.zlabel('Education', fontsize=16)\n",
        "ax.set_xlabel('Education')\n",
        "ax.set_ylabel('Age')\n",
        "ax.set_zlabel('Income')\n",
        "\n",
        "ax.scatter(X[:, 1], X[:, 0], X[:, 3], c= labels.astype(np.float))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBUc8CnICg9Y"
      },
      "source": [
        "Алгоритм $k$-means поділив клієнтів на взаємовиключні групи, наприклад, на 3 кластери. Клієнти в кожному кластері подібні один до одного демографічно. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR5Zn4DXvP5g"
      },
      "source": [
        "Розглянемо як працює алгоритм без оптимізації налаштувань та з оптимізацією"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSBHbCUqmywP"
      },
      "source": [
        "# init 3 clusters without optimization\n",
        "kmeans = KMeans(\n",
        "    n_clusters=3, \n",
        "    init='random',\n",
        "    max_iter=1,\n",
        "    n_init=1,    \n",
        "    # random_state=RANDOM_SEED\n",
        ")\n",
        "kmeans = kmeans.fit(X)\n",
        "clabels = kmeans.predict(X)\n",
        "kmeans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK8R8Vsvm5Lc"
      },
      "source": [
        "area = np.pi * ( X[:, 1])**2  \n",
        "plt.scatter(X[:, 0], X[:, 3], s=area, c=clabels.astype(np.float), alpha=0.5)\n",
        "plt.xlabel('Age', fontsize=18)\n",
        "plt.ylabel('Income', fontsize=16)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS16yAqinrjR"
      },
      "source": [
        "# init 3 clusters with optimization\n",
        "kmeans = KMeans(\n",
        "    n_clusters=3, \n",
        "    max_iter=100,\n",
        "    n_init=10,    \n",
        "    # random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "kmeans.fit(X)\n",
        "clabels = kmeans.predict(X)\n",
        "kmeans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpsEbhp5n289"
      },
      "source": [
        "area = np.pi * ( X[:, 1])**2  \n",
        "plt.scatter(X[:, 0], X[:, 3], s=area, c=clabels.astype(np.float), alpha=0.5)\n",
        "plt.xlabel('Age', fontsize=18)\n",
        "plt.ylabel('Income', fontsize=16)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kl8zgmDGo_-3"
      },
      "source": [
        "# кількість кластерів k та значення інерції\n",
        "ks = range(1, 10)\n",
        "inertias = []\n",
        "\n",
        "for k in ks:\n",
        "    model = KMeans(n_clusters=k)\n",
        "    model.fit(X)\n",
        "    inertias.append(model.inertia_)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.style.use('bmh')\n",
        "plt.plot(ks, inertias, '-o')\n",
        "plt.xlabel('Number of clusters, k')\n",
        "plt.ylabel('Inertia')\n",
        "plt.xticks(ks)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}