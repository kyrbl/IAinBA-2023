{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNhBviOWN-YW"
      },
      "source": [
        "<center><font size=\"6\"><b>Комп'ютерний практикум 7.\n",
        "\n",
        "<center><b> Методи класифікації </font>\n",
        "\n",
        "\n",
        "<center><b><i><font size=\"4\"> KNN (K Nearest Neighbors Algorithm)\n",
        "\n",
        "DT (Decision Tree Algorithm)</b></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWAXRwMSyONP"
      },
      "source": [
        "##__Навчання з вчителем (Supervised learning)__\n",
        "\n",
        ">__Навчання з вчителем (навчання на розмічених данних)__ - це напрямок машинного навчання, що об'єднує алгоритми і методи побудови моделей на основі набору прикладів, пари «відомий вхід - відомий вихід». Машина навчається на попередньо розмічених данних.\n",
        "\n",
        "___Загальна постановка навчання з вчителем:___\n",
        "\n",
        "Для навчальної вибірки $X=(x_i,y_i)^l_{i=1}$ необхідно знайти такий алгоритм $a\\in \\mathbb A$, на якому буде мінімізуватися функціонал помилки: $$Q(a,X)\\longrightarrow \\min_{a\\in \\mathbb A}$$.\n",
        "\n",
        "<center><img src=\"https://www.diegocalvo.es/wp-content/uploads/2020/02/supervised-learning.png\" width=\"600\"></center>\n",
        "\n",
        "В залежності від множини можливих результатів $\\mathbb Y$, задачі поділяються на декілька типів:\n",
        "\n",
        "* __Задачі регресії__\n",
        "\n",
        "$\\mathbb Y$ є дійсною змінною\n",
        "<center><img src=\"https://higherlogicdownload.s3.amazonaws.com/IMWUC/UploadedImages/92757287-d116-4157-b004-c2a0aba1b048/linear-regression-in-machine-learning.png\" width=\"400\"></center>\n",
        "\n",
        "* __Задача бінарної класифікації__\n",
        "\n",
        "В такій задачі простір результатів складається з пари $\\mathbb Y=\\{0,1\\}$. Множина об'єктів, що мають один з пари результатів, називається ___класом___. Тобто, необхідно віднести об'єкти (класифікувати) до одного з цих класів.\n",
        "\n",
        "<center><img src=\"https://www.kdnuggets.com/wp-content/uploads/toy-binary-dataset.png\" width=\"400\"></center>\n",
        "\n",
        "* __Задача множинної класифікації__\n",
        "\n",
        "Класів більше ніж два\n",
        "\n",
        "<center><img src=\"https://miro.medium.com/max/1506/1*JAXmOAImcf683aXaBDPPVg.jpeg\" width=\"400\"></center>\n",
        "\n",
        "* __Задача ранжування__\n",
        "\n",
        "Формальна постановка задачі:\n",
        "\n",
        "Є вибірка, яка складається з $n$ елементів: $$x_1, . . . , x_n.$$ Вона складається з об'єктів, які мають факторний опис, як і в задачах регресії та класифікації. Ключова відмінність ранжування полягає в цільовій змінній: кожному об'єкту необхідно співвіднести пари виду:$$\\{(i, j) :x_i< x_j\\}.$$ Набір таких пар і є цільовою змінною. В задачі необхідно побудувати модель $a(x)$, таку, що:$$x_i< x_j \\Longrightarrow a(x_i)< a(x_j).$$\n",
        "Таким чином, по виходам необхідно встановити порядок, а величина результатів не має значення.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8l9TxG3N2Tzq"
      },
      "source": [
        "##__Задачі класифікації__\n",
        "\n",
        "Задача класифікації в машинному навчанні — це задача співставлення об'єкту до одного з наперед заданих класів, на основі його формалізованих ознак. Кожен з об'єктів в такій задачі представляє собою вектор в  $N$-вимірному просторі, кожен вимір якого є опис однієї ознаки об'єкта. \n",
        "\n",
        "Для навчання класифікатору необхідно попередньо поділити всю вибірку даних на тренувальну та тестову, де наперед визначені класи.\n",
        "\n",
        ">__Найпоширеніші алгоритми для задач класифікації__\n",
        "\n",
        "* $k$-найближчих сусідів (kNN - $k$-Nearest Neighbors)\n",
        "* Дерево рішень (DT-Decision Tree)\n",
        "* Логістична регресія (Logistic Regression)\n",
        "* Метод опорних векторів (SVM - Support Vector Machine)\n",
        "* Линійний дискримінантний аналіз LDA (Linear Discriminant Analysis).\n",
        "* Наївний баєсів класифікатор (Naive Bayes Classifier)\n",
        "* Беггінг та випадковий ліс (Bagging, Random Forest)\n",
        "* Бустинг та AdaBoost (Boosting)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtM5UAzB8LpF"
      },
      "source": [
        "##__$k$-найближчих сусідів (kNN - $k$-Nearest Neighbors)__\n",
        "\n",
        "Найпростіший метричний метод в задачах класифікації, його суть полягає в тому, що нова точка відноситься до того ж класу, що і найближча точка з навчальної вибірки.\n",
        "<center><img src=\"https://www.machinelearningmastery.ru/img/0-917935-124414.png\" width=\"400\"></center>\n",
        "\n",
        "___Етапи алгоритму:___\n",
        "1. розрахувати відстань до кожного з об'єктів навчальної вибірки \n",
        "2. визначити $k$ об'єктів навчальної вибірки, відстань до яких мінімальна\n",
        "3. визначити клас об'єкта, що класифікується — це клас, який найчастіше зустрічається серед $k$ найближчих сусідів\n",
        "\n",
        "Для реалізації алгоритму необхідно визначити оптимальну кількість $k$ сусідів та метрику для розрахунку \"близькості\" елементів.\n",
        "\n",
        "__МЕТРИКА (відстань)__\n",
        "\n",
        "* __Евклідова метрика__\n",
        "$$\\rho(x, y)=\\sqrt{\\sum_{i=1}^n{(x_i-y_i)^2}} $$\n",
        "* __Манхеттенська метрика ($L_1$)__\n",
        "$$\\rho(x, y)=\\sum_{i=1}^n{|x_i-y_i|} $$\n",
        "<center><img src=\"https://cdnb.20m.es/mati-una-profesora-muy-particular/files/2013/04/bilateros_2.jpg\" width=\"400\"></center>\n",
        "\n",
        "* __Метрика Мінковського__\n",
        "$$\\rho(x, y)=\\left(\\sum_{i=1}^n{|x_i-y_i|^q} \\right)^{1/q}$$\n",
        "\n",
        "$q=1$ - Манхетенська метрика\n",
        "\n",
        "$q=2$ - Евклідова метрика\n",
        "\n",
        "$q=\\infty$ - Метрика Чебишева\n",
        "<center><img src=\"https://www.researchgate.net/publication/349155159/figure/fig1/AS:989596292767746@1612949550717/Three-typical-Minkowski-distances-ie-Euclidean-Manhattan-and-Chebyshev-distances.png\" width=\"400\"></center>\n",
        "\n",
        "__Вибір оптимального $k$__\n",
        "\n",
        "1. В загальному випадку не існує способу визначення найкращого значення для $k$, тому необхідно спробувати кілька значень, перш ніж зупинитися на одному. \n",
        "\n",
        "2. Невеликі значення $k$ можуть бути зашумленими і піддаватися впливу викидів.\n",
        "\n",
        "3. Більші значення $k$ матимуть більш плавні межі прийняття рішень, що означатиме меншу дисперсію, але збільшення зміщенності.\n",
        " \n",
        "4. Використати алгоритм крос-валідації для визначення $k$.\n",
        " \n",
        "5. Спробувати зберегти значення $k$ непарним, щоб уникнути плутанини між двома класами даних\n",
        "\n",
        "<center><img src=\"https://miro.medium.com/max/622/1*fFKbGPgzexQ8Tzpm5FEMrg.png\" width=\"400\"></center>\n",
        "\n",
        "Частота помилок навчання та коефіцієнт помилок валідації-це два параметри, які нам потрібні для доступу до різних $k$-значень. Нижче наведена крива частоти помилок навчання з різним значенням $k$:\n",
        "\n",
        "<center><img src=\"https://www.analyticsvidhya.com/wp-content/uploads/2014/10/training-error.png\" width=\"600\"></center>\n",
        "\n",
        "Як бачите, коефіцієнт помилок при $k = 1$ завжди є нульовим для навчальної вибірки. Це тому, що найближчою точкою до будь - якої точки навчальних даних є вона сама. Тому прогноз завжди точний з $k = 1$. Нижче наведена крива помилки валідації зі змінним значенням $k$:\n",
        "<center><img src=\"https://www.analyticsvidhya.com/wp-content/uploads/2014/10/training-error_11.png\" width=\"600\"></center>\n",
        "\n",
        "Рівень помилок спочатку зменшується і досягає мінімуму. Після точки мінімуму вона потім збільшується зі збільшенням $k$. Щоб отримати оптимальне значення $k$, можна поділити вибірку на навчальну та тестову, побудувати криву помилки валідації, щоб отримати оптимальне значення $k$. \n",
        "\n",
        "\n",
        "Алгоритм kNN може потребувати значної кількості  пам'яті для зберігання всих даних. Метод може погано працювати з багатовимірними даними (множиною вхідних змінних), що негативно впливає на ефективність алгоритму, краще його застосовувати лише на найбільш вагомих ознаках. Також неякісні результати роботи алгоритму можна отримати на зашумлених даних.\n",
        "\n",
        "Для покращення роботи алгоритму можна вводити ваги на сусідів (зважений алгоритм kNN), як функцію від номеру елемента, або як функцію від відстані. Також можна вводити центроїдний класифікатор: спочатку визначаються центроїди класів, а потім об'єкт класифікується в залежності від близькості до певного центроїда.\n",
        "\n",
        "### __Переваги методу__\n",
        "\n",
        "1. Простий у реалізації\n",
        "2. Гнучкий вибір функцій/відстані\n",
        "3. Добре працює з багатокласовим випадком\n",
        "4. Добре працює на лінійно нероздільних даних\n",
        "5. Може мати хороші результати на практиці, маючи достатньо репрезентативних даних\n",
        "\n",
        "### __Недоліки методу__\n",
        "\n",
        "1. Значні затрати пам'яті, алгоритм зберігає всі навчальні дані\n",
        "4. Стадія прогнозування може бути повільною (з великою розмірністю $N$)\n",
        "5. Чутливий до невідповідних ознак, викидів та масштабу даних\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUBEZYM2Vi7D"
      },
      "source": [
        "##__Реалізація алгоритму kNN__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSxaxbOfQT9K"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSZnBBBNGHnO"
      },
      "source": [
        "__Завантажимо дані__\n",
        "\n",
        "Телекомунікаційний провайдер сегментував свою базу клієнтів за ознаками використання послуг, класифікуючи клієнтів на чотири групи. Якщо демографічні дані можна використовувати для прогнозування відношення до групи, компанія може налаштувати пропозиції для окремих потенційних клієнтів. \n",
        "Враховуючи набір даних із заздалегідь визначеними мітками, потрібно побудувати модель, яка буде використовуватися для прогнозування класу нового чи невідомого випадку.\n",
        "\n",
        "У прикладі використано демографічні дані, такі як регіон, вік та шлюб.\n",
        "\n",
        "Цільове поле, яке називається `custcat`, має чотири можливі значення, які відповідають чотирьом групам клієнтів:\n",
        "\n",
        "`1- Basic Service 2- E-Service 3- Plus Service 4- Total Service`\n",
        "\n",
        "__Мета__ - створити класифікатор, передбачити клас невідомих випадків."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fwRvv_3Np1f"
      },
      "source": [
        "path='https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/teleCust1000t.csv'\n",
        "df_knn = pd.read_csv(path)\n",
        "df_knn.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC8cLnyL6WT3"
      },
      "source": [
        "# Порахуємо кількість даних в кожному класі\n",
        "df_knn['custcat'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ6y3CtZDEur"
      },
      "source": [
        "#Визначимо множину ознак\n",
        "df_knn.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI1x7i9RDLBi"
      },
      "source": [
        "#Сформуємо масив ознак без цільової змінної\n",
        "X_knn= df_knn[['region', 'tenure','age', 'marital', 'address', 'income', 'ed', 'employ','retire', 'gender', 'reside']] .values \n",
        "X_knn[0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syxAScvdIRlx"
      },
      "source": [
        "#Сформуємо вектор цільової змінної\n",
        "y_knn = df_knn['custcat'].values\n",
        "y_knn[0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiloJ7sdIbzN"
      },
      "source": [
        "#Проведемо стандартизацію даних для кращого представлення даних для алгоритму kNN\n",
        "X_knn = preprocessing.StandardScaler().fit(X_knn).transform(X_knn.astype(float))\n",
        "X_knn[0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeLWiH3iIyXl"
      },
      "source": [
        "# Поділимо вибірку на навчальну та тестову в пропорції 80/20\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_knn_train, X_knn_test, y_knn_train, y_knn_test = train_test_split( X_knn, y_knn, test_size=0.2, random_state=4)\n",
        "print ('Навчальна вибірка:', X_knn_train.shape,  y_knn_train.shape)\n",
        "print ('Тестова вибірка:', X_knn_test.shape,  y_knn_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWDKIy4ASv_P"
      },
      "source": [
        "# Імпортуємо бібліотеку для KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApZlFZmtS1WP"
      },
      "source": [
        "# візьмемо k=3\n",
        "# p=1 - Мангеттенська метрика (по замовчуванню), р=2 - Евклідова метрика, довільне р - метрика Мінковського\n",
        "k = 3\n",
        "neigh = KNeighborsClassifier(n_neighbors = k, p=1).fit(X_knn_train,y_knn_train)\n",
        "neigh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9XAkY3WTMJ1"
      },
      "source": [
        "# зробимо прогноз \n",
        "\n",
        "yhat_knn = neigh.predict(X_knn_test)\n",
        "yhat_knn[0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWMFphiOTWfu"
      },
      "source": [
        "# оцінимо точність прогнозу\n",
        "\n",
        "from sklearn import metrics\n",
        "print(\"Точність на навчальних даних: \", metrics.accuracy_score(y_knn_train, neigh.predict(X_knn_train)))\n",
        "print(\"Точність на тестових даних: \", metrics.accuracy_score(y_knn_test, yhat_knn))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBKbidGnfQwX"
      },
      "source": [
        "###__Вибір $k$__\n",
        "\n",
        "Застосуємо функцію `GridSearchCV` для автоматичного вибору $k$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck1S4mRYavf9"
      },
      "source": [
        "# імпортуємо Pipeline для лінійного об'єднання необхідних процесів\n",
        "from sklearn.pipeline import Pipeline "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q16-BlvTaxKK"
      },
      "source": [
        "# сформуємо модель, яку хочемо навчити\n",
        "knn_pipe = Pipeline([('scaler', preprocessing.StandardScaler()), ('knn', KNeighborsClassifier())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d3PS9b8a5a7"
      },
      "source": [
        "# визначимо параметр, який будемо обирати (кількість сусідів k від 1-9)\n",
        "knn_params = {'knn__n_neighbors': range(1, 10)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-vHfwR8bJLf"
      },
      "source": [
        "# імпортуємо GridSearchCV для визначення k\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_hAF8nfa8-B"
      },
      "source": [
        "# задамо параметри для GridSearchCV\n",
        "knn_grid = GridSearchCV(knn_pipe, knn_params,\n",
        "cv=5)\n",
        "# параметр сv задає кількість підмножин для крос-валідації"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eid5U824bLTz"
      },
      "source": [
        "# навчаємо модель\n",
        "knn_grid.fit(X_knn_train, y_knn_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKmjIFVfbQLr"
      },
      "source": [
        "# визначаємо найкраще k та точність на навчальних даних\n",
        "knn_grid.best_params_, knn_grid.best_score_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdienJt4bTMk"
      },
      "source": [
        "# визначаємо точність на тестових даних\n",
        "metrics.accuracy_score(y_knn_test, knn_grid.predict(X_knn_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0CLqV2G3yxz"
      },
      "source": [
        "##__Дерево рішень (DT-Decision Tree)__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27pxOUlpZ6rI"
      },
      "source": [
        "\n",
        "\n",
        "<center><img src=\"https://www.jcchouinard.com/wp-content/uploads/2021/11/image-1.png.webp\" width=\"400\"></img></center>\n",
        "\n",
        "Дерево рішень як алгоритм машинного навчання – об'єднання логічних правил виду \"Значення ознаки $a$ меньше за $x$ та \"Значення ознаки $b$ меньше за $y$… $\\Longrightarrow$ _Клас 1_\" в структуру даних \"Дерево\". \n",
        "\n",
        "Дерева рішень легко інтерпретуються на відміну від інших моделей, які працюють скоріш як \"чорний ящик\", в який завантажили дані та отримали відповідь. Також дерево рішень працює як з неперервними, так і з категоріальними даними.\n",
        "\n",
        "\n",
        "___Етапи алгоритму:___\n",
        "\n",
        "1. Для кожного вузла:\n",
        "\n",
        "  1.1. Вибирається фактор з набору даних. \n",
        "\n",
        "  1.2. Обчислюється значимість цього фактору (приріст інформації) при розбитті даних на класи.\n",
        "\n",
        "  1.3 Повторюється для кожного фактору.\n",
        "\n",
        "2. Розподіляються дані за фактором, який є найбільш значущим (найбільший приріст інформації).\n",
        "\n",
        "3. Повторюється процедура, доки ентропія не буде дорівнювати або буде близькою до $0$.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yx3OKEEpHYg"
      },
      "source": [
        "__Ентропія__ – це міра хаосу або невизначеності.\n",
        "$$H(X)=-\\sum_{i=1}^n{p_i\\log_2{p_i}}$$\n",
        "$p_i=\\frac{N_i}{N}$ – це частотна ймовірність належності даних до класу $i$, де $N_i$ - кількість об'єктів у класі $N$ - кількість даних всього, $n$ - кількість класів. \n",
        "\n",
        "<center><img src=\"https://miro.medium.com/max/750/1*M15RZMSk8nGEyOnD8haF-A.png\" width=\"400\"></img></center>\n",
        "\n",
        "__Інформаційний приріст (Information Gain)__ - величина для виміру зменшення хаосу в додатковій інформації (ознаках/незалежних змінних) цільової змінної/класу:\n",
        "\n",
        "$$IG=(Y,X)=H(Y)-H(Y|X)$$\n",
        "\n",
        "<center><img src=\"https://miro.medium.com/max/954/0*EfweHd4gB5j6tbsS.png\" width=\"400\"></img></center>\n",
        "\n",
        "\n",
        "__Індекс Джині (Gini impurity)__ - метрика розбиття дерева рішень. Ймовірність того, що випадково обраний елемент із набору даних буде невірно класифікований.\n",
        "$$Gini=1-\\sum_{i=1}^n{(p_i)^2}$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buzq3-Jszqa5"
      },
      "source": [
        "##__Реалізація алгоритму DT__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh7jDdxezjuS"
      },
      "source": [
        "#Імпортуємо функцію для дерева рішень\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTZWZ2h20nQa"
      },
      "source": [
        "__Завантажимо дані__\n",
        "Датасет містить дані про пацієнтів, які страждали однією хворобою. Під час курсу лікування кожен пацієнт реагував на один із 5 препаратів: препарат А, препарат В, препарат С, препарат Х та Y.\n",
        "\n",
        "Побудувати модель, щоб з'ясувати, який препарат може підходити майбутньому пацієнту з тією ж хворобою. Маємо наступні фактори: вік, стать, артеріальний тиск та рівень холестерину у пацієнтів, цільова змінна (клас) - препарат, на який реагував кожен пацієнт.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z3FQN_m0mm8"
      },
      "source": [
        "path='https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/drug200.csv'\n",
        "df_dt= pd.read_csv(path)\n",
        "df_dt.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4YHe7E72BCs"
      },
      "source": [
        "#Сформуємо масив ознак без цільової змінної\n",
        "X_dt = df_dt[['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K']].values\n",
        "X_dt[0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0iXpTcl2f3g"
      },
      "source": [
        "Набір даних містить категоріальні змінні такі як стать `Sex`, артеріальний тиск `BP` та рівень холестирину `Cholesterol`. Модуль для побудови дерева рішень з бібліотеки `Sklearn` не обробляє категоріальні змінні, тому закодуємо їх  (фіктивними\\індикаторними) за допомогою `pandas.get_dummies ()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YteEYLdN2PhX"
      },
      "source": [
        "# кодування категоріальних змінних\n",
        "from sklearn import preprocessing\n",
        "le_sex = preprocessing.LabelEncoder()\n",
        "le_sex.fit(['F','M'])\n",
        "X_dt[:,1] = le_sex.transform(X_dt[:,1]) \n",
        "\n",
        "\n",
        "le_BP = preprocessing.LabelEncoder()\n",
        "le_BP.fit([ 'LOW', 'NORMAL', 'HIGH'])\n",
        "X_dt[:,2] = le_BP.transform(X_dt[:,2])\n",
        "\n",
        "\n",
        "le_Chol = preprocessing.LabelEncoder()\n",
        "le_Chol.fit([ 'NORMAL', 'HIGH'])\n",
        "X_dt[:,3] = le_Chol.transform(X_dt[:,3]) \n",
        "\n",
        "X_dt[0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ngrpHfr4DX9"
      },
      "source": [
        "#Сформуємо множину цільової змінної\n",
        "y_dt =df_dt[\"Drug\"]\n",
        "y_dt[0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdf7jB1t4aNY"
      },
      "source": [
        "# Поділимо вибірку на навчальну та тестову в пропорції 80/20\n",
        "X_dt_train, X_dt_test, y_dt_train, y_dt_test = train_test_split(X_dt, y_dt, test_size=0.2, random_state=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jjIi0yD6VSs"
      },
      "source": [
        "#оберемо параметри моделі для класифікації\n",
        "Tree = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "Tree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbMGwPAB6fsK"
      },
      "source": [
        "# Навчимо модель\n",
        "Tree.fit(X_dt_train,y_dt_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlVkkVW66nxu"
      },
      "source": [
        "# Зробимо прогноз\n",
        "predTree =Tree.predict(X_dt_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElJIhdV96nvX"
      },
      "source": [
        "print (predTree [0:5])\n",
        "print (y_dt_test [0:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqlGIOxO6_BU"
      },
      "source": [
        "# оцінимо точність прогнозу\n",
        "print(\"Точність дерева рішень: \", metrics.accuracy_score(y_dt_test, predTree))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tKH4z-L-aym"
      },
      "source": [
        "names_X=df_dt[['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWXUfVGD8zpp"
      },
      "source": [
        "from sklearn import tree\n",
        "plt.figure(figsize=(10,10))\n",
        "tree.plot_tree(Tree,  filled=True,\n",
        "               feature_names=names_X.columns.tolist(),\n",
        "               class_names=['A', 'B', 'C', 'X','Y'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPG6Sax-AkQg"
      },
      "source": [
        "# змінимо критерій поділу на 'gini'\n",
        "Tree_1= DecisionTreeClassifier(criterion=\"gini\",max_depth=4)\n",
        "Tree_1.fit(X_dt_train,y_dt_train)\n",
        "predTree_1 =Tree_1.predict(X_dt_test)\n",
        "print(\"Точність дерева рішень: \", metrics.accuracy_score(y_dt_test, predTree_1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmkkn93wByjG"
      },
      "source": [
        "from sklearn import tree\n",
        "plt.figure(figsize=(10,10))\n",
        "tree.plot_tree(Tree_1,  filled=True,\n",
        "               feature_names=names_X.columns.tolist(),\n",
        "               class_names=['A', 'B', 'C', 'X','Y'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAZGJnXVFXRn"
      },
      "source": [
        "###__Вибір глибини дерева та кількості факторів__\n",
        "\n",
        "Застосуємо функцію `GridSearchCV` для автоматичного вибору"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29PPv_WUCAdq"
      },
      "source": [
        "# визначимо параметри, які будемо обирати (глибина від 1 до 5, кількість факторів від 1 до 5)\n",
        "tree_params = {'max_depth': range(1,6),\n",
        "'max_features': range(1,6)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz6nLK7dDv0X"
      },
      "source": [
        "# задамо параметри для GridSearchCV\n",
        "tree_grid = GridSearchCV(Tree_1, tree_params,\n",
        "cv=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfASM2xpD0lx"
      },
      "source": [
        "# навчаємо модель\n",
        "tree_grid.fit(X_dt_train, y_dt_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJa4Le6iEXhs"
      },
      "source": [
        "# визначаємо оптимальні параметри\n",
        "tree_grid.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xX1FaLdEbVQ"
      },
      "source": [
        "# визначаємо точність на навчальних даних\n",
        "tree_grid.best_score_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJX7X3PgEhfe"
      },
      "source": [
        "# визначаємо точність на тестових даних\n",
        "metrics.accuracy_score(y_dt_test, tree_grid.predict(X_dt_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEoeTCVzgj0O"
      },
      "source": [
        "##<center>__Самостійні завдання__</center>\n",
        "\n",
        "> Скопіювати блок самостійних завдань в окремий файл ***LastName_CP7.ipynb***\n",
        "\n",
        "> Інсталюйте необхідні пакети бібліотек Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BDe0NyTgmSY"
      },
      "source": [
        "### Завдання №1\n",
        "\n",
        "* Завантажте дані з лінку\n",
        "\n",
        "`url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"`\n",
        "\n",
        "<center><img src=\"http://sebastianraschka.com/images/blog/2015/principal_component_analysis_files/iris.png\" width=\"600\" alt=\"content-vs-colab.png\"></center>\n",
        "\n",
        "* задайте наступні імена колонок датафрейму:\n",
        "\n",
        "`names=['sepal length','sepal width','petal length','petal width','class label']`\n",
        "* виведіть описову статистику датасету\n",
        "* сформуйте масив характеристик $X$ та цільової змінної/класу $Y$ \n",
        "* виведіть кількість елементів у кожному класі\n",
        "* поділіть вибірку на навчальну та тестову у співвідношенні 30/70\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0XIjMe_gpOr"
      },
      "source": [
        "# МІСЦЕ ДЛЯ КОДУ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5xD3xxVpvNI"
      },
      "source": [
        "### Завдання №2\n",
        "\n",
        "* Проведіть стандартизацію даних\n",
        "* застосуйте алгоритм kNN для $k=3$, $k=5$, використовуючи евклідову метрику та манхеттенську метрику\n",
        "* порівняйте результати точності для цих моделей\n",
        "* визначіть оптимальне $k$ за допомогою `GridSearchCV`\n",
        "* зробіть висновки\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_V_77Igpzgi"
      },
      "source": [
        "# МІСЦЕ ДЛЯ КОДУ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIoUG_3wp8pG"
      },
      "source": [
        "### Завдання №3\n",
        "\n",
        "* Проведіть стандартизацію даних\n",
        "* застосуйте алгоритм дерева рішень з критерієм `entropy` \n",
        "* візуалізуйте дерево\n",
        "* оцініть точність класифікації\n",
        "* застосуйте алгоритм дерева рішень з критерієм `gini` \n",
        "* візуалізуйте дерево\n",
        "* оцініть точність класифікації\n",
        "* визначіть оптимальну кількість характеристик в моделі та глибину дерева за допомогою `GridSearchCV`\n",
        "* зробіть висновки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fB9yio-tp1eu"
      },
      "source": [
        "# МІСЦЕ ДЛЯ КОДУ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFWpAKfmu9nv"
      },
      "source": [
        "### Завдання №4\n",
        "\n",
        "Порівняйте результати класифікації методами kNN та дерева рішень для заданого набору даних"
      ]
    }
  ]
}